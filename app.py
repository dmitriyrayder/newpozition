import streamlit as st
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import optuna

# --- –°–¢–ò–õ–ò–ó–ê–¶–ò–Ø –ò–ù–¢–ï–†–§–ï–ô–°–ê ---
st.set_page_config(page_title="–ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫", layout="wide", initial_sidebar_state="collapsed")

st.markdown("""
<style>
/* –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–Ω –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è */
.main { background-color: #fce4ec; }
h1 { font-family: 'Comic Sans MS', cursive, sans-serif; color: #e91e63; text-align: center; text-shadow: 2px 2px 4px #f8bbd0; }
h2, h3 { font-family: 'Comic Sans MS', cursive, sans-serif; color: #ad1457; }
.stButton>button {
    color: white; background-image: linear-gradient(to right, #f06292, #e91e63); border-radius: 25px;
    border: 2px solid #ad1457; padding: 12px 28px; font-weight: bold; font-size: 18px;
    box-shadow: 0 4px 15px 0 rgba(233, 30, 99, 0.4); transition: all 0.3s ease 0s;
}
.stButton>button:hover { background-position: right center; box-shadow: 0 4px 15px 0 rgba(233, 30, 99, 0.75); }
.stExpander { border: 2px solid #f8bbd0; border-radius: 10px; background-color: #fff1f8; }
</style>
""", unsafe_allow_html=True)

st.title("üíñ –ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫ –ø–æ –ü—Ä–æ–¥–∞–∂–∞–º üíñ")

# --- –ë–õ–û–ö –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–• –§–£–ù–ö–¶–ò–ô ---

@st.cache_data
def process_and_aggregate(_df, art_col, magazin_col, date_col, qty_col, price_col, cat_features_tuple):
    df = _df.copy()
    cat_features = list(cat_features_tuple)
    column_map = {
        art_col: 'Art', magazin_col: 'Magazin', date_col: 'date', qty_col: 'Qty', price_col: 'Price'
    }
    df.rename(columns=column_map, inplace=True)
    initial_rows = len(df)
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    bad_date_rows = df['date'].isna().sum()
    df.dropna(subset=['date'], inplace=True)
    crucial_cols = ['Qty', 'Art', 'Magazin', 'Price']
    df.dropna(subset=crucial_cols, inplace=True)
    df = df.sort_values(by=['Art', 'Magazin', 'date'])
    series_of_first_dates = df.groupby(['Art', 'Magazin'])['date'].first()
    first_sale_dates = series_of_first_dates.reset_index(name='first_sale_date')
    df_merged = pd.merge(df, first_sale_dates, on=['Art', 'Magazin'])
    df_30_days = df_merged[df_merged['date'] <= (df_merged['first_sale_date'] + pd.Timedelta(days=30))].copy()
    agg_logic = {'Qty': 'sum', 'Price': 'mean'}
    for cat_col in cat_features:
        agg_logic[cat_col] = 'first'
    df_agg = df_30_days.groupby(['Art', 'Magazin'], as_index=False).agg(agg_logic)
    df_agg.rename(columns={'Qty': 'Qty_30_days'}, inplace=True)
    stats = {
        "total_rows": initial_rows, "final_rows": len(df_agg), "bad_date_rows": bad_date_rows
    }
    return df_agg, stats

@st.cache_resource
def train_model_with_optuna(_df_agg, cat_features_tuple):
    # --- –ù–û–í–ò–ù–ö–ê: URL –¥–ª—è –≥–∏—Ñ–∫–∏ —Å –±–æ–∂—å–µ–π –∫–æ—Ä–æ–≤–∫–æ–π ---
    LADYBUG_GIF_URL = "https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExd2RzZW9sZHZvb3J1MnJjc2Y1ZjFwZ3g4dzF3d21xbXFmd3N5eXU2eCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9cw/L1554O3V2iI5a/giphy.gif"
    
    cat_features = list(cat_features_tuple)
    target = 'Qty_30_days'
    features = ['Magazin', 'Price'] + cat_features
    df_processed = _df_agg[features + [target]]
    all_cat_features = ['Magazin'] + cat_features
    for col in all_cat_features:
        df_processed[col] = df_processed[col].astype(str)
    X, y = df_processed[features], df_processed[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

    # --- –ù–û–í–ò–ù–ö–ê: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥–∏—Ñ–∫—É –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è ---
    with st.spinner("üîÆ –ö–æ–ª–¥—É—é –Ω–∞–¥ –º–æ–¥–µ–ª—å—é... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –º–∏–Ω—É—Ç–∫—É..."):
        st.image(LADYBUG_GIF_URL, width=150)
        optuna.logging.set_verbosity(optuna.logging.WARNING)
        study = optuna.create_study(direction='minimize')
        study.optimize(lambda trial: mean_absolute_error(y_test, CatBoostRegressor(
            iterations=1000, learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),
            depth=trial.suggest_int('depth', 4, 10), verbose=0, random_seed=42
        ).fit(X_train, y_train, cat_features=all_cat_features, eval_set=(X_test, y_test), early_stopping_rounds=50, use_best_model=True).predict(X_test)), n_trials=30)
    
    st.success(f"–í–æ–ª—à–µ–±—Å—Ç–≤–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ! üí´ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {study.best_params}")
    final_model = CatBoostRegressor(**study.best_params, iterations=1500, verbose=0, random_seed=42).fit(X, y, cat_features=all_cat_features)
    test_preds = final_model.predict(X_test)
    return final_model, features, {'MAE': mean_absolute_error(y_test, test_preds), 'R2': r2_score(y_test, test_preds)}

# --- –û–°–ù–û–í–ù–û–ô –ë–õ–û–ö STREAMLIT ---

if 'processed' not in st.session_state:
    st.session_state.processed = False

dataset_file = st.file_uploader("üíñ –ó–∞–≥—Ä—É–∑–∏ —Å–≤–æ–π —Ñ–∞–π–ª —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏ (.xlsx, .xls, .csv)", type=["csv", "xlsx", "xls"])

if dataset_file:
    try:
        if dataset_file.name.endswith('.csv'):
            df_raw = pd.read_csv(dataset_file)
        else:
            df_raw = pd.read_excel(dataset_file, engine='openpyxl')
        st.session_state.df_raw = df_raw
    except Exception as e:
        st.error(f"–ù–µ –º–æ–≥—É –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª, –¥–æ—Ä–æ–≥–∞—è! –û—à–∏–±–∫–∞: {e}")
        st.stop()
    
    st.subheader("–®–∞–≥ 1: –ü–æ–º–æ–≥–∏ –º–Ω–µ –ø–æ–Ω—è—Ç—å —Ç–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ üßê")
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏, –∫–∞–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ç–≤–æ–µ–º —Ñ–∞–π–ª–µ –∑–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞—é—Ç. –≠—Ç–æ –æ—á–µ–Ω—å –≤–∞–∂–Ω–æ! üôè")
    
    all_columns = st.session_state.df_raw.columns.tolist()
    
    with st.form("mapping_form"):
        col1, col2 = st.columns(2)
        with col1:
            art_col = st.selectbox("–ê—Ä—Ç–∏–∫—É–ª —Ç–æ–≤–∞—Ä–∞ (ID)", all_columns, index=min(0, len(all_columns)-1))
            magazin_col = st.selectbox("–ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞", all_columns, index=min(1, len(all_columns)-1))
            date_col = st.selectbox("–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏", all_columns, index=min(2, len(all_columns)-1))
        with col2:
            qty_col = st.selectbox("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥–∞–Ω–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ (—à—Ç.)", all_columns, index=min(3, len(all_columns)-1))
            price_col = st.selectbox("–¶–µ–Ω–∞ —Ç–æ–≤–∞—Ä–∞", all_columns, index=min(4, len(all_columns)-1))
        
        available_features = [c for c in all_columns if c not in [art_col, magazin_col, date_col, qty_col, price_col]]
        cat_features_selected = st.multiselect(
            "–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ç–æ–≤–∞—Ä–∞ (–≤—ã–±–µ—Ä–∏ –≤—Å–µ, —á—Ç–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–æ–≤–∞—Ä)",
            available_features,
            help="–í—ã–±–µ—Ä–∏ –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–æ–¥–µ '–ë—Ä–µ–Ω–¥', '–¶–≤–µ—Ç', '–ú–∞—Ç–µ—Ä–∏–∞–ª', '–°–µ–≥–º–µ–Ω—Ç' –∏ —Ç.–¥."
        )
        submitted_mapping = st.form_submit_button("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å üöÄ")

    if submitted_mapping:
        cat_features_tuple = tuple(cat_features_selected)
        df_agg, stats = process_and_aggregate(
            st.session_state.df_raw, art_col, magazin_col, date_col, qty_col, price_col, cat_features_tuple
        )
        with st.expander("üìä –°–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ...", expanded=True):
            st.metric("–°—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ üíÖ", f"{stats['total_rows']}")
            st.metric("–°—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ üíé", f"{stats['final_rows']}")
            st.metric("–°—Ç—Ä–æ–∫ —Å –ø–ª–æ—Ö–æ–π –¥–∞—Ç–æ–π üóëÔ∏è", f"{stats['bad_date_rows']}")
        st.session_state.df_agg = df_agg
        st.session_state.cat_features_selected = cat_features_selected
        model, features, metrics = train_model_with_optuna(df_agg, cat_features_tuple)
        st.session_state.model = model
        st.session_state.features = features
        st.session_state.metrics = metrics
        st.session_state.processed = True
        st.rerun()

if st.session_state.processed:
    st.subheader("–®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ üßô‚Äç‚ôÄÔ∏è")
    st.header("üìä –û—Ü–µ–Ω–∫–∞ –º–æ–µ–π —Ä–∞–±–æ—Ç—ã")
    metrics = st.session_state.metrics
    col1, col2 = st.columns(2)
    col1.metric("–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ (MAE)", f"{metrics['MAE']:.2f} —à—Ç.", "+/- —Å—Ç–æ–ª—å–∫–æ —è –º–æ–≥—É –æ—à–∏–±–∏—Ç—å—Å—è")
    col2.metric("–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (R¬≤)", f"{metrics['R2']:.2%}", "—á–µ–º –±–ª–∏–∂–µ –∫ 100%, —Ç–µ–º –ª—É—á—à–µ!")

    st.header("‚úçÔ∏è –û–ø–∏—à–∏ —Å–≤–æ—é –Ω–æ–≤—É—é –±–ª–µ—Å—Ç—è—â—É—é –º–æ–¥–µ–ª—å –æ—á–∫–æ–≤")
    with st.form("prediction_form"):
        new_product_data = {}
        # --- –ù–û–í–ò–ù–ö–ê: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è –≤–≤–æ–¥–∞ —Å –ø–æ–¥—Å–∫–∞–∑–∫–∞–º–∏ ---
        st.info("–í–≤–µ–¥–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –±—ã–ª–æ —Ä–∞–Ω—å—à–µ!")
        
        # –†–∞–∑–¥–µ–ª–∏–º –Ω–∞ –¥–≤–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã
        form_cols = st.columns(2)
        
        # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –Ω–∞ –®–∞–≥–µ 1
        for i, feature in enumerate(st.session_state.cat_features_selected):
            # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–∏–º–µ—Ä –∏–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–¥—Å–∫–∞–∑–∫–∏
            example_values = st.session_state.df_agg[feature].dropna().unique()
            help_text = f"–ù–∞–ø—Ä–∏–º–µ—Ä: {example_values[0]}" if len(example_values) > 0 else "–í–≤–µ–¥–∏ –∑–Ω–∞—á–µ–Ω–∏–µ"
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª—è –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º
            with form_cols[i % 2]:
                new_product_data[feature] = st.text_input(f"{feature} ‚ú®", help=help_text)

        # –ü–æ–ª–µ –¥–ª—è —Ü–µ–Ω—ã –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
        with form_cols[len(st.session_state.cat_features_selected) % 2]:
             new_product_data['Price'] = st.number_input("–¶–µ–Ω–∞ üí∞", min_value=0.0, step=100.0, format="%.2f")
        
        submitted_prediction = st.form_submit_button("–ù–∞–π—Ç–∏ –ª—É—á—à–∏–µ –±—É—Ç–∏–∫–∏! üöÄ")

    if submitted_prediction:
        df_agg = st.session_state.df_agg
        model = st.session_state.model
        features = st.session_state.features
        magaziny = df_agg['Magazin'].unique()
        recs_list = []
        for magazin in magaziny:
            row = new_product_data.copy()
            row['Magazin'] = magazin
            recs_list.append(row)
        recs_df = pd.DataFrame(recs_list)[features]
        recs_df['Pred_Qty_30_days'] = np.maximum(0, model.predict(recs_df).round(0))
        max_pred = recs_df['Pred_Qty_30_days'].max()
        recs_df['Rating_%'] = (recs_df['Pred_Qty_30_days'] / max_pred * 100).round(0) if max_pred > 0 else 0
        top_magaziny = recs_df.sort_values(by='Pred_Qty_30_days', ascending=False).rename(columns={
            'Magazin': '–ë—É—Ç–∏–∫', 'Pred_Qty_30_days': '–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)', 'Rating_%': '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)'
        })
        st.subheader("üéâ –í–æ—Ç –ª—É—á—à–∏–µ –º–µ—Å—Ç–∞ –¥–ª—è —Ç–≤–æ–µ–π –Ω–æ–≤–∏–Ω–∫–∏! üéâ")
        st.dataframe(top_magaziny[['–ë—É—Ç–∏–∫', '–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)', '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)']].style.highlight_max(
            subset=['–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)'], color='#f8bbd0', axis=0
        ).format({'–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)': '{:.0f}', '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)': '{:.0f}%'}), use_container_width=True)
else:
    if not dataset_file:
        st.info("üíã –ü—Ä–∏–≤–µ—Ç! –ó–∞–≥—Ä—É–∑–∏ —Ñ–∞–π–ª–∏–∫, –∞ –ø–æ—Ç–æ–º –ø–æ–º–æ–≥–∏ –º–Ω–µ –ø–æ–Ω—è—Ç—å, –≥–¥–µ –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ.")
