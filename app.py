import streamlit as st
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import optuna

# --- –°–¢–ò–õ–ò–ó–ê–¶–ò–Ø –ò–ù–¢–ï–†–§–ï–ô–°–ê ---
st.set_page_config(page_title="–ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫", layout="wide", initial_sidebar_state="collapsed")

st.markdown("""
<style>
/* –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–Ω –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è */
.main {
    background-color: #fce4ec; /* –ù–µ–∂–Ω–æ-—Ä–æ–∑–æ–≤—ã–π */
}
/* –ó–∞–≥–æ–ª–æ–≤–æ–∫ H1 */
h1 {
    font-family: 'Comic Sans MS', cursive, sans-serif;
    color: #e91e63; /* –Ø—Ä–∫–æ-—Ä–æ–∑–æ–≤—ã–π */
    text-align: center;
    text-shadow: 2px 2px 4px #f8bbd0;
}
/* –ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏ H2, H3 */
h2, h3 {
    font-family: 'Comic Sans MS', cursive, sans-serif;
    color: #ad1457; /* –ì–ª—É–±–æ–∫–∏–π —Ä–æ–∑–æ–≤—ã–π */
}
/* –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫–Ω–æ–ø–∫–∏ */
.stButton>button {
    color: white;
    background-image: linear-gradient(to right, #f06292, #e91e63);
    border-radius: 25px;
    border: 2px solid #ad1457;
    padding: 12px 28px;
    font-weight: bold;
    font-size: 18px;
    box-shadow: 0 4px 15px 0 rgba(233, 30, 99, 0.4);
    transition: all 0.3s ease 0s;
}
.stButton>button:hover {
    background-position: right center;
    box-shadow: 0 4px 15px 0 rgba(233, 30, 99, 0.75);
}
/* –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ Expander */
.stExpander {
    border: 2px solid #f8bbd0;
    border-radius: 10px;
    background-color: #fff1f8;
}
</style>
""", unsafe_allow_html=True)

st.title("üíñ –ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫ –ø–æ –ü—Ä–æ–¥–∞–∂–∞–º üíñ")

# --- –ë–õ–û–ö –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–• –§–£–ù–ö–¶–ò–ô ---

def find_and_convert_date_column(df):
    potential_date_cols = ['Datasales', 'datasales', 'date', 'Date', '–î–∞—Ç–∞', '–¥–∞—Ç–∞_–ø—Ä–æ–¥–∞–∂–∏', 'timestamp']
    for col_name in potential_date_cols:
        if col_name in df.columns:
            st.info(f"–ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π: '{col_name}'. –ü—Ä–µ–æ–±—Ä–∞–∑—É—é... ‚ú®")
            try:
                df[col_name] = pd.to_datetime(df[col_name], errors='coerce')
                if df[col_name].notna().sum() / len(df) > 0.8: return df, col_name
            except Exception: continue
    
    st.warning("–ù–µ –Ω–∞—à–ª–∞ –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–æ–π –ø–æ –∏–º–µ–Ω–∏, –∏—â—É –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É...")
    for col_name in df.select_dtypes(include=['object']).columns:
        try:
            converted_col = pd.to_datetime(df[col_name], errors='coerce')
            if converted_col.notna().sum() / len(df) > 0.8:
                st.success(f"–ù–∞—à–ª–∞! ‚ú® –ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π: '{col_name}'.")
                df[col_name] = converted_col
                return df, col_name
        except Exception: continue
    return df, None

def display_data_stats(df_raw, df_clean, date_col_name):
    with st.expander("üìä –°–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ...", expanded=True):
        col1, col2, col3 = st.columns(3)
        col1.metric("–°—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ üíÖ", f"{len(df_raw)}")
        col2.metric("–°—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ üíé", f"{len(df_clean)}")
        col3.metric("–£–¥–∞–ª–µ–Ω–æ –ª–∏—à–Ω–∏—Ö üóëÔ∏è", f"{len(df_raw) - len(df_clean)}")
        st.success(f"""
        - **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—á–∫–æ–≤:** {df_clean['Art'].nunique()} üï∂Ô∏è
        - **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—É—Ç–∏–∫–æ–≤:** {df_clean['Magazin'].nunique()} üè¨
        - **–ü–µ—Ä–∏–æ–¥ –ø—Ä–æ–¥–∞–∂:** —Å {df_clean[date_col_name].min().strftime('%d.%m.%Y')} –ø–æ {df_clean[date_col_name].max().strftime('%d.%m.%Y')} üóìÔ∏è
        """)

@st.cache_data
def load_and_prepare_data(uploaded_file):
    try:
        # –ß—Ç–µ–Ω–∏–µ CSV –∏–ª–∏ Excel
        if uploaded_file.name.endswith('.csv'):
            df_raw = pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            df_raw = pd.read_excel(uploaded_file, engine='openpyxl')
        else:
            st.error("–û–π! –Ø –Ω–µ –∑–Ω–∞—é —Ç–∞–∫–æ–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ü–æ–ø—Ä–æ–±—É–π .csv, .xlsx –∏–ª–∏ .xls üéÄ")
            return None
    except Exception as e:
        st.error(f"–ù–µ –º–æ–≥—É –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª, –¥–æ—Ä–æ–≥–∞—è! –û—à–∏–±–∫–∞: {e}")
        return None

    df, date_col_name = find_and_convert_date_column(df_raw.copy())
    if not date_col_name:
        st.error("–ù–µ –Ω–∞—à–ª–∞ –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–æ–π –≤ —Ñ–∞–π–ª–µ. –ü—Ä–æ–≤–µ—Ä—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞! ü•∫")
        return None
    
    crucial_cols = ['Qty', 'Art', 'Magazin', date_col_name]
    df_clean = df.dropna(subset=crucial_cols).copy()
    display_data_stats(df_raw, df_clean, date_col_name)

    st.info("–ê–≥—Ä–µ–≥–∏—Ä—É—é –ø—Ä–æ–¥–∞–∂–∏ –∑–∞ –ø–µ—Ä–≤—ã–µ 30 –¥–Ω–µ–π... –ú–∞–≥–∏—è –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ! ‚ú®")
    df_clean = df_clean.sort_values(by=['Art', 'Magazin', date_col_name])
    
    # --- –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ë–õ–û–ö –î–õ–Ø –ò–ó–ë–ï–ñ–ê–ù–ò–Ø –û–®–ò–ë–ö–ò ---
    # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Ä–∏—é —Å –ø–µ—Ä–≤—ã–º–∏ –¥–∞—Ç–∞–º–∏
    series_of_first_dates = df_clean.groupby(['Art', 'Magazin'])[date_col_name].first()
    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å, —Å—Ä–∞–∑—É –¥–∞–≤–∞—è —Å—Ç–æ–ª–±—Ü—É —Å –¥–∞—Ç–∞–º–∏ –Ω–æ–≤–æ–µ –∏–º—è 'first_sale_date'
    first_sale_dates = series_of_first_dates.reset_index(name='first_sale_date')
    # --- –ö–û–ù–ï–¶ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ì–û –ë–õ–û–ö–ê ---
    
    df_merged = pd.merge(df_clean, first_sale_dates, on=['Art', 'Magazin'])
    df_30_days = df_merged[df_merged[date_col_name] <= (df_merged['first_sale_date'] + pd.Timedelta(days=30))].copy()

    agg_logic = {
        'Qty': 'sum', 'Sum': 'sum', 'Price': 'mean', 'Model': 'first', 'brand': 'first', 
        'Segment': 'first', 'color': 'first', 'formaoprav': 'first', 'Sex': 'first', 'Metal-Plastic': 'first'
    }
    df_agg = df_30_days.groupby(['Art', 'Magazin'], as_index=False).agg(agg_logic)
    df_agg.rename(columns={'Qty': 'Qty_30_days'}, inplace=True)
    return df_agg

@st.cache_resource
def train_model_with_optuna(_df_agg):
    target, cat_features = 'Qty_30_days', ['Magazin', 'brand', 'Segment', 'color', 'formaoprav', 'Sex', 'Metal-Plastic']
    df_processed = _df_agg.drop(columns=['Sum', 'Art', 'Model'], errors='ignore')
    features = [col for col in df_processed.columns if col != target]
    for col in cat_features:
        if col in df_processed.columns: df_processed[col] = df_processed[col].astype(str)

    X, y = df_processed[features], df_processed[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

    with st.spinner("üîÆ –ü–æ–¥–±–∏—Ä–∞—é –ª—É—á—à–∏–µ –≤–æ–ª—à–µ–±–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏..."):
        optuna.logging.set_verbosity(optuna.logging.WARNING)
        study = optuna.create_study(direction='minimize')
        study.optimize(lambda trial: mean_absolute_error(y_test, CatBoostRegressor(
            iterations=1000, learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),
            depth=trial.suggest_int('depth', 4, 10), verbose=0, random_seed=42
        ).fit(X_train, y_train, cat_features=cat_features, eval_set=(X_test, y_test), early_stopping_rounds=50, use_best_model=True).predict(X_test)), n_trials=30)
    
    st.success(f"–í–æ–ª—à–µ–±—Å—Ç–≤–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ! üí´ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {study.best_params}")
    final_model = CatBoostRegressor(**study.best_params, iterations=1500, verbose=0, random_seed=42).fit(X, y, cat_features=cat_features)
    test_preds = final_model.predict(X_test)
    return final_model, features, {'MAE': mean_absolute_error(y_test, test_preds), 'R2': r2_score(y_test, test_preds)}

# --- –û–°–ù–û–í–ù–û–ô –ë–õ–û–ö STREAMLIT ---

dataset_file = st.file_uploader("üíñ –ó–∞–≥—Ä—É–∑–∏ —Å–≤–æ–π —Ñ–∞–π–ª —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏ (.xlsx, .xls, .csv)", type=["csv", "xlsx", "xls"])

if dataset_file:
    df_agg = load_and_prepare_data(dataset_file)
    if df_agg is not None and not df_agg.empty:
        model, features, metrics = train_model_with_optuna(df_agg)
        if model:
            st.header("üìä –û—Ü–µ–Ω–∫–∞ –º–æ–µ–π —Ä–∞–±–æ—Ç—ã")
            col1, col2 = st.columns(2)
            col1.metric("–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ (MAE)", f"{metrics['MAE']:.2f} —à—Ç.", "+/- —Å—Ç–æ–ª—å–∫–æ —è –º–æ–≥—É –æ—à–∏–±–∏—Ç—å—Å—è")
            col2.metric("–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (R¬≤)", f"{metrics['R2']:.2%}", "—á–µ–º –±–ª–∏–∂–µ –∫ 100%, —Ç–µ–º –ª—É—á—à–µ!")

            st.header("‚úçÔ∏è –û–ø–∏—à–∏ —Å–≤–æ—é –Ω–æ–≤—É—é –±–ª–µ—Å—Ç—è—â—É—é –º–æ–¥–µ–ª—å –æ—á–∫–æ–≤")
            with st.form("product_form"):
                col1, col2 = st.columns(2)
                with col1:
                    brand = st.text_input("–ë—Ä–µ–Ω–¥ üëë", help="–ù–∞–ø—Ä–∏–º–µ—Ä, Miu Miu")
                    forma = st.text_input("–§–æ—Ä–º–∞ –æ–ø—Ä–∞–≤—ã üëì", help="–ù–∞–ø—Ä–∏–º–µ—Ä, –ö–æ—à–∞—á–∏–π –≥–ª–∞–∑")
                    sex = st.selectbox("–î–ª—è –∫–æ–≥–æ? üë†", df_agg['Sex'].unique())
                    price = st.number_input("–¶–µ–Ω–∞ üí∞", min_value=0.0, step=100.0, format="%.2f")
                with col2:
                    segment = st.selectbox("–°–µ–≥–º–µ–Ω—Ç üíÖ", df_agg['Segment'].unique())
                    color = st.text_input("–¶–≤–µ—Ç üåà", help="–ù–∞–ø—Ä–∏–º–µ—Ä, –†–æ–∑–æ–≤—ã–π")
                    material = st.selectbox("–ú–∞—Ç–µ—Ä–∏–∞–ª ‚ú®", df_agg['Metal-Plastic'].unique())
                submitted = st.form_submit_button("–ù–∞–π—Ç–∏ –ª—É—á—à–∏–µ –±—É—Ç–∏–∫–∏! üöÄ")

            if submitted:
                magaziny = df_agg['Magazin'].unique()
                new_product_data = {'brand': brand, 'Segment': segment, 'color': color, 'formaoprav': forma,
                                    'Sex': sex, 'Metal-Plastic': material, 'Price': price}
                recs_df = pd.DataFrame([dict(item, Magazin=mag) for mag in magaziny for item in [new_product_data]])[features]
                recs_df['Pred_Qty_30_days'] = np.maximum(0, model.predict(recs_df).round(0))
                max_pred = recs_df['Pred_Qty_30_days'].max()
                recs_df['Rating_%'] = (recs_df['Pred_Qty_30_days'] / max_pred * 100).round(0) if max_pred > 0 else 0
                
                top_magaziny = recs_df.sort_values(by='Pred_Qty_30_days', ascending=False).rename(columns={
                    'Magazin': '–ë—É—Ç–∏–∫', 'Pred_Qty_30_days': '–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)', 'Rating_%': '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)'
                })

                st.subheader("üéâ –í–æ—Ç –ª—É—á—à–∏–µ –º–µ—Å—Ç–∞ –¥–ª—è —Ç–≤–æ–µ–π –Ω–æ–≤–∏–Ω–∫–∏! üéâ")
                st.dataframe(top_magaziny[['–ë—É—Ç–∏–∫', '–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)', '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)']].style.highlight_max(
                    subset=['–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)'], color='#f8bbd0', axis=0
                ).format({'–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)': '{:.0f}', '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)': '{:.0f}%'}), use_container_width=True)
else:
    st.info("üíã –ü—Ä–∏–≤–µ—Ç! –ó–∞–≥—Ä—É–∑–∏ —Ñ–∞–π–ª–∏–∫, –∏ —è –ø–æ–º–æ–≥—É —Ç–µ–±–µ —Å—Ç–∞—Ç—å –∑–≤–µ–∑–¥–æ–π –ø—Ä–æ–¥–∞–∂!")
