import streamlit as st
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import optuna

# –û—Ç–∫–ª—é—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ Optuna –≤ –∫–æ–Ω—Å–æ–ª–∏
optuna.logging.set_verbosity(optuna.logging.WARNING)

st.set_page_config(page_title="–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–æ—Ä –º–∞–≥–∞–∑–∏–Ω–æ–≤", layout="wide")

st.title("üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–æ—Ä –º–∞–≥–∞–∑–∏–Ω–æ–≤ –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ç–æ–≤–∞—Ä–∞")

# --- –ë–õ–û–ö –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–• –§–£–ù–ö–¶–ò–ô ---

def find_and_convert_date_column(df):
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–∞–º–∏.
    –°–Ω–∞—á–∞–ª–∞ –∏—â–µ—Ç –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º –∏–º–µ–Ω–∞–º, –∑–∞—Ç–µ–º –ø—ã—Ç–∞–µ—Ç—Å—è –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å object-–∫–æ–ª–æ–Ω–∫–∏.
    """
    potential_date_cols = ['Datasales', 'datasales', 'date', 'Date', '–î–∞—Ç–∞', '–¥–∞—Ç–∞_–ø—Ä–æ–¥–∞–∂–∏', 'timestamp']
    
    # –ü–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∏
    for col_name in potential_date_cols:
        if col_name in df.columns:
            st.info(f"–ù–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π: '{col_name}'. –ü–æ–ø—ã—Ç–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏...")
            try:
                # errors='coerce' –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç –Ω–µ—É–¥–∞—á–Ω—ã–µ –ø–∞—Ä—Å–∏–Ω–≥–∏ –≤ NaT (Not a Time)
                df[col_name] = pd.to_datetime(df[col_name], errors='coerce')
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –ø–æ—á—Ç–∏ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–∞–ª–∏–¥–Ω—ã, —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ —É—Å–ø–µ—Ö–æ–º
                if df[col_name].notna().sum() / len(df) > 0.8:
                    return df, col_name
            except Exception:
                continue # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é

    # –ï—Å–ª–∏ –ø–æ –∏–º–µ–Ω–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
    st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–æ–π. –ü—ã—Ç–∞—é—Å—å –Ω–∞–π—Ç–∏ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É...")
    for col_name in df.select_dtypes(include=['object']).columns:
        try:
            converted_col = pd.to_datetime(df[col_name], errors='coerce')
            # –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –±–æ–ª–µ–µ 80% —Å—Ç—Ä–æ–∫, —Å—á–∏—Ç–∞–µ–º –∫–æ–ª–æ–Ω–∫—É –¥–∞—Ç–æ–π
            if converted_col.notna().sum() / len(df) > 0.8:
                st.info(f"–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π: '{col_name}'.")
                df[col_name] = converted_col
                return df, col_name
        except Exception:
            continue
            
    return df, None

def display_data_stats(df_raw, df_clean, date_col_name):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É."""
    with st.expander("üîç –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º", expanded=True):
        initial_rows = len(df_raw)
        clean_rows = len(df_clean)
        dropped_rows = initial_rows - clean_rows
        
        col1, col2, col3 = st.columns(3)
        col1.metric("–°—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ", f"{initial_rows}")
        col2.metric("–°—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏", f"{clean_rows}", help="–£–¥–∞–ª–µ–Ω—ã —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏ –≤ 'Qty', 'Art', 'Magazin' –∏–ª–∏ –¥–∞—Ç–µ.")
        col3.metric("–£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫", f"{dropped_rows}")
        
        st.info(f"""
        - **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (Art):** {df_clean['Art'].nunique()}
        - **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤ (Magazin):** {df_clean['Magazin'].nunique()}
        - **–ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö:** —Å {df_clean[date_col_name].min().strftime('%d.%m.%Y')} –ø–æ {df_clean[date_col_name].max().strftime('%d.%m.%Y')}
        """)

@st.cache_data
def load_and_prepare_data(uploaded_file):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—á–∏—â–∞–µ—Ç –∏ –∞–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ."""
    try:
        df_raw = pd.read_xlsx(uploaded_file)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return None

    # 1. –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ü–û–ò–°–ö –ò –ö–û–ù–í–ï–†–¢–ê–¶–ò–Ø –î–ê–¢–´
    df, date_col_name = find_and_convert_date_column(df_raw.copy())
    if not date_col_name:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É —Å –¥–∞—Ç–æ–π –≤ –≤–∞—à–µ–º —Ñ–∞–π–ª–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
        return None
    
    # 2. –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–•
    crucial_cols = ['Qty', 'Art', 'Magazin', date_col_name]
    df_clean = df.dropna(subset=crucial_cols).copy()
    
    # 3. –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò
    display_data_stats(df_raw, df_clean, date_col_name)

    # 4. –ê–ì–†–ï–ì–ê–¶–ò–Ø –î–ê–ù–ù–´–• (–ü–†–û–î–ê–ñ–ò –ó–ê –ü–ï–†–í–´–ï 30 –î–ù–ï–ô)
    st.info("–ê–≥—Ä–µ–≥–∏—Ä—É—é –ø—Ä–æ–¥–∞–∂–∏ –∑–∞ –ø–µ—Ä–≤—ã–µ 30 –¥–Ω–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –≤ –∫–∞–∂–¥–æ–º –º–∞–≥–∞–∑–∏–Ω–µ...")
    df_clean = df_clean.sort_values(by=['Art', 'Magazin', date_col_name])
    first_sale_dates = df_clean.groupby(['Art', 'Magazin'])[date_col_name].first().reset_index()
    first_sale_dates.rename(columns={date_col_name: 'first_sale_date'}, inplace=True)
    
    df_merged = pd.merge(df_clean, first_sale_dates, on=['Art', 'Magazin'])
    df_30_days = df_merged[df_merged[date_col_name] <= (df_merged['first_sale_date'] + pd.Timedelta(days=30))].copy()

    agg_logic = {
        'Qty': 'sum', 'Sum': 'sum', 'Price': 'mean', 'Model': 'first',
        'brand': 'first', 'Segment': 'first', 'color': 'first',
        'formaoprav': 'first', 'Sex': 'first', 'Metal-Plastic': 'first'
    }
    df_agg = df_30_days.groupby(['Art', 'Magazin'], as_index=False).agg(agg_logic)
    df_agg.rename(columns={'Qty': 'Qty_30_days'}, inplace=True)
    
    return df_agg

@st.cache_resource
def train_model_with_optuna(_df_agg):
    """–ü—Ä–æ–≤–æ–¥–∏—Ç –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –æ–±—É—á–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å."""
    target = 'Qty_30_days'
    cat_features = ['Magazin', 'brand', 'Segment', 'color', 'formaoprav', 'Sex', 'Metal-Plastic']
    drop_cols = ['Sum', 'Art', 'Model'] 
    
    df_processed = _df_agg.drop(columns=drop_cols, errors='ignore')
    features = [col for col in df_processed.columns if col != target]
    
    for col in cat_features:
        if col in df_processed.columns:
            df_processed[col] = df_processed[col].astype(str)

    X = df_processed[features]
    y = df_processed[target]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

    st.info("–ó–∞–ø—É—Å–∫–∞—é –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é Optuna...")
    
    def objective(trial):
        params = {
            'iterations': 1000,
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
            'depth': trial.suggest_int('depth', 4, 10),
            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0, log=True),
            'verbose': 0, 'random_seed': 42
        }
        model = CatBoostRegressor(**params)
        model.fit(X_train, y_train, cat_features=cat_features, eval_set=(X_test, y_test), early_stopping_rounds=50, use_best_model=True)
        return mean_absolute_error(y_test, model.predict(X_test))

    study = optuna.create_study(direction='minimize')
    study.optimize(objective, n_trials=30, show_progress_bar=True)
    
    best_params = study.best_params
    st.success(f"–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞–π–¥–µ–Ω—ã: {best_params}")

    st.info("–û–±—É—á–∞—é —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö...")
    final_model = CatBoostRegressor(**best_params, iterations=1500, verbose=0, random_seed=42)
    final_model.fit(X, y, cat_features=cat_features)

    test_preds = final_model.predict(X_test)
    metrics = {'MAE': mean_absolute_error(y_test, test_preds), 'R2': r2_score(y_test, test_preds)}
    
    return final_model, features, cat_features, metrics

# --- –û–°–ù–û–í–ù–û–ô –ë–õ–û–ö STREAMLIT ---

dataset_file = st.file_uploader("\U0001F4C2 –ó–∞–≥—Ä—É–∑–∏—Ç–µ xlsx-—Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö", type=["xlsx"])

if dataset_file:
    df_agg = load_and_prepare_data(dataset_file)
    
    if df_agg is not None and not df_agg.empty:
        model, features, cat_features, metrics = train_model_with_optuna(df_agg)

        if model:
            st.header("üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏")
            col1, col2 = st.columns(2)
            col1.metric("–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (MAE)", f"{metrics['MAE']:.2f} —à—Ç.")
            col2.metric("–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ (R¬≤)", f"{metrics['R2']:.2%}")
            st.caption("MAE –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞ —Å–∫–æ–ª—å–∫–æ —à—Ç—É–∫ –≤ —Å—Ä–µ–¥–Ω–µ–º –æ—à–∏–±–∞–µ—Ç—Å—è –ø—Ä–æ–≥–Ω–æ–∑ –∑–∞ 30 –¥–Ω–µ–π. R¬≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫—É—é –¥–æ–ª—é –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –æ–±—ä—è—Å–Ω—è–µ—Ç –º–æ–¥–µ–ª—å.")

            st.header("‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–æ–≤–æ–≥–æ —Ç–æ–≤–∞—Ä–∞")
            with st.form("product_form"):
                col1, col2 = st.columns(2)
                with col1:
                    brand = st.text_input("Brand (–±—Ä–µ–Ω–¥)", help="–ù–∞–ø—Ä–∏–º–µ—Ä, Ray-Ban")
                    forma = st.text_input("Forma oprav (—Ñ–æ—Ä–º–∞ –æ–ø—Ä–∞–≤—ã)", help="–ù–∞–ø—Ä–∏–º–µ—Ä, –ê–≤–∏–∞—Ç–æ—Ä")
                    sex = st.selectbox("Sex (–ø–æ–ª)", df_agg['Sex'].unique())
                    price = st.number_input("Price (—Ü–µ–Ω–∞)", min_value=0.0, step=100.0, format="%.2f")
                with col2:
                    segment = st.selectbox("Segment (—Å–µ–≥–º–µ–Ω—Ç)", df_agg['Segment'].unique())
                    color = st.text_input("Color (—Ü–≤–µ—Ç)", help="–ù–∞–ø—Ä–∏–º–µ—Ä, –ß–µ—Ä–Ω—ã–π")
                    material = st.selectbox("Metal-Plastic (–º–∞—Ç–µ—Ä–∏–∞–ª)", df_agg['Metal-Plastic'].unique())
                
                submitted = st.form_submit_button("üöÄ –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")

            if submitted:
                magaziny = df_agg['Magazin'].unique()
                new_product_data = {'brand': brand, 'Segment': segment, 'color': color, 'formaoprav': forma,
                                    'Sex': sex, 'Metal-Plastic': material, 'Price': price}
                
                recs_list = [dict(item, Magazin=mag) for mag in magaziny for item in [new_product_data]]
                recs_df = pd.DataFrame(recs_list)[features]

                recs_df['Pred_Qty_30_days'] = np.maximum(0, model.predict(recs_df).round(0))
                
                max_pred = recs_df['Pred_Qty_30_days'].max()
                recs_df['Rating_%'] = (recs_df['Pred_Qty_30_days'] / max_pred * 100).round(0) if max_pred > 0 else 0
                
                top_magaziny = recs_df.sort_values(by='Pred_Qty_30_days', ascending=False).reset_index(drop=True)

                st.subheader("\U0001F4C8 –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ –º–∞–≥–∞–∑–∏–Ω—ã –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ç–æ–≤–∞—Ä–∞")
                st.table(top_magaziny[['Magazin', 'Pred_Qty_30_days', 'Rating_%']].rename(columns={
                    'Magazin': '–ú–∞–≥–∞–∑–∏–Ω', 'Pred_Qty_30_days': '–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)', 'Rating_%': '–†–µ–π—Ç–∏–Ω–≥ (%)'
                }))
else:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã.")
