import streamlit as st
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import optuna
import plotly.express as px
import re

# ==============================================================================
# 1. –°–¢–†–£–ö–¢–£–†–ê –ò–ù–¢–ï–†–§–ï–ô–°–ê –ò –°–¢–ò–õ–ò
# ==============================================================================
st.set_page_config(page_title="–ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫", layout="wide", initial_sidebar_state="expanded")

st.markdown("""
<style>
/* –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–Ω –∏ —à—Ä–∏—Ñ—Ç—ã */
body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji"; }
.main { background-color: #f0f2f6; }
/* –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫–Ω–æ–ø–æ–∫ */
.stButton>button {
    border-radius: 8px; border: 2px solid #ff4b4b; color: #ff4b4b;
    background-color: transparent; font-weight: bold; transition: all 0.3s;
}
.stButton>button:hover {
    border-color: #ff4b4b; color: white; background-color: #ff4b4b;
}
/* –°—Ç–∏–ª—å –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π –∫–Ω–æ–ø–∫–∏ (type="primary") */
div[data-testid="stForm"] .stButton>button[kind="primary"] {
    border-color: #ff4b4b; color: white; background-color: #ff4b4b;
}
</style>
""", unsafe_allow_html=True)

# ==============================================================================
# 8. –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ß–ê–°–¢–¨: –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ==============================================================================

def auto_detect_column(columns, keywords, default_index=0):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º."""
    if not columns:
        return 0
    
    for keyword in keywords:
        for i, col in enumerate(columns):
            if keyword.lower() in col.lower():
                return i
    return min(default_index, len(columns) - 1)

def extract_features_from_description(descriptions_str):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è.
       –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —É–∂–µ –æ—á–∏—â–µ–Ω–Ω—É—é —Å–µ—Ä–∏—é —Å—Ç—Ä–æ–∫."""
    features = pd.DataFrame(index=descriptions_str.index)
    extraction_map = {
        'brand_extracted': ['ray-ban', 'oakley', 'gucci', 'prada', 'polaroid'],
        'material_extracted': ['–º–µ—Ç–∞–ª–ª', '–ø–ª–∞—Å—Ç–∏–∫', '–¥–µ—Ä–µ–≤–æ', '–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π'],
        'shape_extracted': ['–∞–≤–∏–∞—Ç–æ—Ä', '–≤–∞–π—Ñ–∞—Ä–µ—Ä', '–∫—Ä—É–≥–ª—ã–µ', '–∫–æ—à–∞—á–∏–π –≥–ª–∞–∑']
    }
    for feature_name, keywords in extraction_map.items():
        pattern = re.compile(f'({"|".join(keywords)})', re.IGNORECASE)
        features[feature_name] = descriptions_str.str.findall(pattern).str[0].str.lower().fillna('–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')
    return features

@st.cache_data
def process_data_and_train(_df, column_map, feature_config):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ, –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏, –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å.
    """
    try:
        df = _df.copy()
        
        # --- –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê: –°–ù–ê–ß–ê–õ–ê –ò–ó–í–õ–ï–ö–ê–ï–ú, –ü–û–¢–û–ú –ü–ï–†–ï–ò–ú–ï–ù–û–í–´–í–ê–ï–ú ---

        # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ú –∏–º–µ–Ω–∞–º –∫–æ–ª–æ–Ω–æ–∫
        all_features_df = pd.DataFrame(index=df.index)
        
        if feature_config['describe_col'] != "–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å":
            user_selected_describe_col = feature_config['describe_col']
            if user_selected_describe_col in df.columns:
                describe_series = df[user_selected_describe_col].astype(str).fillna('')
                extracted = extract_features_from_description(describe_series)
                all_features_df = pd.concat([all_features_df, extracted], axis=1)

        for feature, source_col in feature_config['manual_features'].items():
            if source_col and source_col in df.columns:
                all_features_df[feature] = df[source_col].astype(str).fillna('–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')

        # 2. –¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã, –ü–ï–†–ï–ò–ú–ï–ù–û–í–´–í–ê–ï–ú –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ–º
        valid_column_map = {k: v for k, v in column_map.items() if v and v in df.columns}
        df.rename(columns={v: k for k, v in valid_column_map.items()}, inplace=True)

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
        required_cols = ['date', 'Art', 'Magazin', 'Qty', 'Price']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            return None, None, None, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: {missing_cols}"

        # 3. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –æ—á–∏—Å—Ç–∫–∞ —É–∂–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df.dropna(subset=['date', 'Art', 'Magazin', 'Qty', 'Price'], inplace=True)
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Å—Ç–∞–ª–∏—Å—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
        if len(df) == 0:
            return None, None, None, "–í—Å–µ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç –∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π."
        
        df['Price'] = pd.to_numeric(df['Price'], errors='coerce').fillna(0)
        df['Qty'] = pd.to_numeric(df['Qty'], errors='coerce').fillna(0)
        
        # 4. –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        df_with_features = pd.concat([df[['Art', 'Magazin', 'date', 'Qty', 'Price']], all_features_df], axis=1)
        df_with_features.dropna(subset=['Art', 'Magazin'], inplace=True) 

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Å—Ç–∞–ª–∏—Å—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è
        if len(df_with_features) == 0:
            return None, None, None, "–î–∞–Ω–Ω—ã–µ –ø–æ—Ç–µ—Ä—è–ª–∏—Å—å –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏."

        df_with_features = df_with_features.sort_values(by=['Art', 'Magazin', 'date'])
        first_sale_dates = df_with_features.groupby(['Art', 'Magazin'])['date'].first().reset_index(name='first_sale_date')
        df_merged = pd.merge(df_with_features, first_sale_dates, on=['Art', 'Magazin'])
        df_30_days = df_merged[df_merged['date'] <= (df_merged['first_sale_date'] + pd.Timedelta(days=30))].copy()

        agg_logic = {'Qty': 'sum', 'Price': 'mean'}
        feature_cols = [col for col in all_features_df.columns if col in df_30_days.columns]
        for col in feature_cols:
            agg_logic[col] = 'first'
        
        df_agg = df_30_days.groupby(['Art', 'Magazin'], as_index=False).agg(agg_logic)
        df_agg.rename(columns={'Qty': 'Qty_30_days'}, inplace=True)

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
        if len(df_agg) < 10:
            return None, None, None, f"–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(df_agg)} –∑–∞–ø–∏—Å–µ–π. –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 10."

        # 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        target = 'Qty_30_days'
        cat_features_to_use = ['Magazin'] + feature_cols
        features_to_use = ['Price'] + cat_features_to_use
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö
        missing_features = [f for f in features_to_use if f not in df_agg.columns]
        if missing_features:
            return None, None, None, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {missing_features}"
        
        X = df_agg[features_to_use]
        y = df_agg[target]
        
        for col in cat_features_to_use:
            if col in X.columns:  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–∫–∏
                X[col] = X[col].astype(str)

        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º
        if len(X) < 5:
            return None, None, None, f"–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏: {len(X)} –∑–∞–ø–∏—Å–µ–π."

        test_size = min(0.2, max(0.1, 1.0 / len(X)))  # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
        
        def objective(trial):
            params = {
                'iterations': 100,  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–º–µ–Ω—å—à–∏–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),
                'depth': trial.suggest_int('depth', 3, 6),  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–º–µ–Ω—å—à–∏–ª–∏ –≥–ª—É–±–∏–Ω—É –¥–ª—è –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                'verbose': 0, 
                'random_seed': 42
            }
            try:
                model = CatBoostRegressor(**params)
                model.fit(X_train, y_train, cat_features=[i for i, col in enumerate(features_to_use) if col in cat_features_to_use], 
                         eval_set=(X_test, y_test), early_stopping_rounds=10, use_best_model=True)
                return mean_absolute_error(y_test, model.predict(X_test))
            except Exception as e:
                return float('inf')  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–µ

        study = optuna.create_study(direction='minimize')
        study.optimize(objective, n_trials=10)  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£–º–µ–Ω—å—à–∏–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–±–∞–≤–∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏
        try:
            final_model = CatBoostRegressor(**study.best_params, iterations=200, verbose=0, random_seed=42)
            final_model.fit(X, y, cat_features=[i for i, col in enumerate(features_to_use) if col in cat_features_to_use])
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            y_pred = final_model.predict(X_test)
            metrics = {
                'MAE': mean_absolute_error(y_test, y_pred),
                'R2': max(0, r2_score(y_test, y_pred))  # R2 –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
            }
        except Exception as e:
            return None, None, None, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {str(e)}"
        
        return final_model, features_to_use, metrics, None
        
    except Exception as e:
        return None, None, None, f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}"

# ==============================================================================
# –û–°–ù–û–í–ù–û–ô –ö–û–î –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
# ==============================================================================

st.title("üíñ –ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫ –ø–æ –ü—Ä–æ–¥–∞–∂–∞–º")

# –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session_state
if 'step' not in st.session_state:
    st.session_state.step = 1
if 'df_raw' not in st.session_state:
    st.session_state.df_raw = None

with st.sidebar:
    st.header("1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª Excel –∏–ª–∏ CSV", type=["csv", "xlsx", "xls"])

    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file, encoding='utf-8')
            else:
                df = pd.read_excel(uploaded_file)
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
            if len(df) == 0:
                st.error("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π!")
                st.stop()
            
            st.session_state.df_raw = df
            st.success(f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω! –°—Ç—Ä–æ–∫: {len(df)}, –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö
            with st.expander("–ü—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö"):
                st.dataframe(df.head())
                
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            st.stop()

# –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
if st.session_state.df_raw is not None:
    df_raw = st.session_state.df_raw
    available_columns = df_raw.columns.tolist()

    st.header("2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
    with st.form("column_mapping_form"):
        st.subheader("üéØ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")
        st.caption("–ü–æ–º–æ–≥–∏—Ç–µ –º–Ω–µ –ø–æ–Ω—è—Ç—å, –≥–¥–µ –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è. –Ø –ø–æ–ø—Ä–æ–±—É—é —É–≥–∞–¥–∞—Ç—å —Å–∞–º–∞!")
        c1, c2 = st.columns(2)
        with c1:
            col_magazin = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –ú–ê–ì–ê–ó–ò–ù:", available_columns, 
                                     index=auto_detect_column(available_columns, ['magazin', '–º–∞–≥–∞–∑–∏–Ω', 'store']))
            col_art = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –ê–†–¢–ò–ö–£–õ:", available_columns, 
                                 index=auto_detect_column(available_columns, ['art', '–∞—Ä—Ç–∏–∫—É–ª', 'sku'], 1))
            col_qty = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –ö–û–õ–ò–ß–ï–°–¢–í–û:", available_columns, 
                                 index=auto_detect_column(available_columns, ['qty', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'], 2))
        with c2:
            col_date = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –î–ê–¢–ê –ü–†–û–î–ê–ñ–ò:", available_columns, 
                                  index=auto_detect_column(available_columns, ['datasales', '–¥–∞—Ç–∞', 'date'], 3))
            col_price = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –¶–ï–ù–ê:", available_columns, 
                                   index=auto_detect_column(available_columns, ['price', '—Ü–µ–Ω–∞'], 4))
            col_describe = st.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –û–ü–ò–°–ê–ù–ò–ï –¢–û–í–ê–†–ê:", available_columns + ["–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å"], 
                                      index=auto_detect_column(available_columns, ['describe', '–æ–ø–∏—Å–∞–Ω–∏–µ'], 5))

        st.subheader("‚úã –†—É—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–æ–≤–∞—Ä–∞")
        st.caption("–ö–∞–∫–∏–µ –µ—â–µ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–≤–∞—Ä–µ? (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ë—Ä–µ–Ω–¥, –¶–≤–µ—Ç, –ü–æ–ª)")
        other_feature_cols = st.multiselect(
            "–í—ã–±–µ—Ä–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏-–ø—Ä–∏–∑–Ω–∞–∫–∏:",
            [c for c in available_columns if c not in [col_magazin, col_art, col_qty, col_date, col_price, col_describe]]
        )
        
        submitted = st.form_submit_button("‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –∏ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary")

    if submitted:
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤—ã–±—Ä–∞–Ω—ã
        required_mappings = [col_magazin, col_art, col_qty, col_date, col_price]
        if not all(required_mappings):
            st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏!")
            st.stop()
            
        st.session_state.step = 2
        column_map = {'Magazin': col_magazin, 'Art': col_art, 'date': col_date, 'Qty': col_qty, 'Price': col_price}
        feature_config = {
            'describe_col': col_describe,
            'manual_features': {col: col for col in other_feature_cols}
        }

        with st.spinner("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—É—á–∞—é –º–æ–¥–µ–ª—å..."):
            model, features, metrics, error_msg = process_data_and_train(df_raw, column_map, feature_config)

        if error_msg:
            st.error(error_msg)
        else:
            st.session_state.model = model
            st.session_state.features = features
            st.session_state.metrics = metrics
            st.session_state.all_stores = df_raw[col_magazin].unique()
            st.session_state.feature_config = feature_config
            st.success("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!")
            st.rerun()

# –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º step –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
if st.session_state.step == 2 and 'model' in st.session_state:
    st.header("3. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è")
    metrics = st.session_state.metrics
    c1, c2 = st.columns(2)
    c1.metric("–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ (MAE)", f"{metrics['MAE']:.2f} —à—Ç.")
    c2.metric("–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (R¬≤)", f"{metrics['R2']:.2%}")

    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    try:
        feature_importance = st.session_state.model.get_feature_importance()
        feature_importance_df = pd.DataFrame({
            'feature': st.session_state.features,
            'importance': feature_importance
        }).sort_values('importance', ascending=False)

        fig = px.bar(feature_importance_df, x='importance', y='feature', orientation='h', 
                    title='–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏')
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")

    st.header("4. –í–≤–æ–¥ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
    with st.form("prediction_form"):
        st.subheader("üÜï –í–≤–µ–¥–∏—Ç–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
        new_product_data = {}
        c1, c2 = st.columns(2)
        
        with c1:
            new_product_data['Price'] = st.number_input("üí∞ –¶–µ–Ω–∞ –º–æ–¥–µ–ª–∏:", min_value=0.0, step=100.0, value=1000.0)
        
        manual_features_to_input = list(st.session_state.feature_config['manual_features'].keys())
        for i, feature in enumerate(manual_features_to_input):
            with c1 if (i+1) % 2 != 0 else c2:
                new_product_data[feature] = st.text_input(f"üîπ {feature}:", value="–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω")
                
        if st.session_state.feature_config['describe_col'] != "–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å":
            st.info("–¢–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å —É—á–∏–ª–∞—Å—å –Ω–∞ –∞–≤—Ç–æ-–ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è, –≤–≤–µ–¥–∏—Ç–µ –∏—Ö –≤—Ä—É—á–Ω—É—é:")
            with c2:
                new_product_data['brand_extracted'] = st.text_input("üè∑Ô∏è –ë—Ä–µ–Ω–¥ (–∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è):", value="–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω")
                new_product_data['material_extracted'] = st.text_input("üîß –ú–∞—Ç–µ—Ä–∏–∞–ª (–∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è):", value="–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω")
                new_product_data['shape_extracted'] = st.text_input("üï∂Ô∏è –§–æ—Ä–º–∞ (–∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è):", value="–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω")
        
        predict_button = st.form_submit_button("üéØ –ü–û–î–û–ë–†–ê–¢–¨ –ú–ê–ì–ê–ó–ò–ù–´", type="primary")

    if predict_button:
        try:
            model = st.session_state.model
            features = st.session_state.features
            all_stores = st.session_state.all_stores
            
            prediction_df = pd.DataFrame(columns=features)
            for store in all_stores:
                row = new_product_data.copy()
                row['Magazin'] = str(store)
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ó–∞–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                for f in features:
                    if f not in row:
                        row[f] = '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω'
                
                prediction_df.loc[len(prediction_df)] = row

            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
            cat_features_indices = []
            try:
                cat_features_indices = model.get_cat_feature_indices()
            except:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º
                cat_features_names = ['Magazin'] + [col for col in features if 'extracted' in col or col in st.session_state.feature_config['manual_features']]
                cat_features_indices = [i for i, col in enumerate(features) if col in cat_features_names]
            
            for i, col in enumerate(features):
                if i in cat_features_indices:
                    prediction_df[col] = prediction_df[col].astype(str)
                else:
                    prediction_df[col] = pd.to_numeric(prediction_df[col], errors='coerce').fillna(0)

            predictions = model.predict(prediction_df[features])
            prediction_df['prediction'] = np.maximum(0, predictions)
            
            max_pred = prediction_df['prediction'].max()
            prediction_df['compatibility'] = (prediction_df['prediction'] / max_pred * 100) if max_pred > 0 else 0
            
            results = prediction_df.sort_values('prediction', ascending=False)
            
            st.subheader("üèÜ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–∞–≥–∞–∑–∏–Ω—ã")
            top_results = results.head(min(5, len(results)))
            for idx, (i, row) in enumerate(top_results.iterrows()):
                with st.expander(f"**#{idx+1} {row['Magazin']}** - –ü—Ä–æ–≥–Ω–æ–∑: **{row['prediction']:.0f} —à—Ç/–º–µ—Å**"):
                    c1, c2 = st.columns(2)
                    c1.metric("–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂", f"{row['prediction']:.0f} —à—Ç")
                    c2.metric("–ò–Ω–¥–µ–∫—Å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏", f"{row['compatibility']:.0f}%")
            
            if len(results) > 5:
                st.subheader("‚ùå –ú–µ–Ω–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –º–∞–≥–∞–∑–∏–Ω—ã")
                bottom_results = results.tail(min(3, len(results) - 5))
                for i, row in bottom_results.iterrows():
                    st.markdown(f"- **{row['Magazin']}**: –ü—Ä–æ–≥–Ω–æ–∑ ~{row['prediction']:.0f} —à—Ç/–º–µ—Å. –í–æ–∑–º–æ–∂–Ω–æ, –Ω–µ –ª—É—á—à–∏–π –≤—ã–±–æ—Ä.")
                    
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏: {str(e)}")
            st.error("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–Ω–æ–≤–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–≤–µ–¥–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")

elif st.session_state.step == 1:
    st.info("üëÜ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã.")
else:
    st.warning("–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É.")
