import streamlit as st
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
import re
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="üíñ –ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫", layout="wide", initial_sidebar_state="expanded")

# –ö–∞—Å—Ç–æ–º–Ω—ã–π CSS –¥–ª—è –∫—Ä–∞—Å–Ω—ã—Ö –∫–Ω–æ–ø–æ–∫
st.markdown("""
<style>
.stButton > button {
    background-color: #DC143C;
    color: white;
    border: none;
    border-radius: 10px;
    font-weight: bold;
    font-size: 16px;
    padding: 0.5rem 1rem;
    transition: all 0.3s;
}
.stButton > button:hover {
    background-color: #B22222;
    transform: translateY(-2px);
}
</style>
""", unsafe_allow_html=True)

@st.cache_data
def auto_detect_column(columns, keywords):
    """–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
    for keyword in keywords:
        for i, col in enumerate(columns):
            if keyword.lower() in col.lower():
                return i
    return 0

@st.cache_data
def safe_read_file(uploaded_file):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–∞—Ç"""
    try:
        if uploaded_file.name.endswith('.xlsx'):
            df = pd.read_excel(uploaded_file)
        else:
            df = pd.read_csv(uploaded_file)
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞—Ç—ã
        date_cols = [col for col in df.columns if any(word in col.lower() for word in ['date', '–¥–∞—Ç–∞', 'datasales'])]
        for col in date_cols:
            try:
                df[col] = pd.to_datetime(df[col])
            except:
                df[col] = pd.to_datetime(df[col], errors='coerce')
        
        return df, len(df), 0
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return None, 0, 1

@st.cache_data
def extract_features_from_text(text_series):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è"""
    features = pd.DataFrame(index=text_series.index)
    
    # –ü–æ–ª
    gender_patterns = {
        '–ú—É–∂—Å–∫–∏–µ': r'–º—É–∂—Å–∫|male|men',
        '–ñ–µ–Ω—Å–∫–∏–µ': r'–∂–µ–Ω—Å–∫|female|women|lady',
        '–£–Ω–∏—Å–µ–∫—Å': r'—É–Ω–∏—Å–µ–∫—Å|unisex'
    }
    features['gender'] = '–£–Ω–∏—Å–µ–∫—Å'
    for gender, pattern in gender_patterns.items():
        mask = text_series.str.contains(pattern, case=False, na=False)
        features.loc[mask, 'gender'] = gender
    
    # –ú–∞—Ç–µ—Ä–∏–∞–ª
    material_patterns = {
        '–ú–µ—Ç–∞–ª–ª': r'–º–µ—Ç–∞–ª–ª|metal|steel|—Ç–∏—Ç–∞–Ω',
        '–ü–ª–∞—Å—Ç–∏–∫': r'–ø–ª–∞—Å—Ç–∏–∫|plastic|acetate',
        '–î–µ—Ä–µ–≤–æ': r'–¥–µ—Ä–µ–≤|wood|bamboo'
    }
    features['material'] = '–ü–ª–∞—Å—Ç–∏–∫'
    for material, pattern in material_patterns.items():
        mask = text_series.str.contains(pattern, case=False, na=False)
        features.loc[mask, 'material'] = material
    
    # –§–æ—Ä–º–∞
    shape_patterns = {
        '–ê–≤–∏–∞—Ç–æ—Ä': r'–∞–≤–∏–∞—Ç–æ—Ä|aviator|pilot',
        '–í–∞–π—Ñ–∞—Ä–µ—Ä': r'–≤–∞–π—Ñ–∞—Ä–µ—Ä|wayfarer',
        '–ö—Ä—É–≥–ª—ã–µ': r'–∫—Ä—É–≥–ª|round|circle',
        '–ü—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–µ': r'–ø—Ä—è–º–æ—É–≥|rectangle|square',
        '–ö–æ—à–∞—á–∏–π –≥–ª–∞–∑': r'–∫–æ—à–∞—á|cat.eye'
    }
    features['shape'] = '–ü—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–µ'
    for shape, pattern in shape_patterns.items():
        mask = text_series.str.contains(pattern, case=False, na=False)
        features.loc[mask, 'shape'] = shape
    
    # –ë–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    features['is_polarized'] = text_series.str.contains(r'–ø–æ–ª—è—Ä|polar', case=False, na=False).astype(int)
    features['has_uv'] = text_series.str.contains(r'uv|–∑–∞—â–∏—Ç–∞|protection', case=False, na=False).astype(int)
    
    return features

@st.cache_data
def create_store_profiles(df, store_col, price_col, date_col, qty_col):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π –º–∞–≥–∞–∑–∏–Ω–æ–≤"""
    profiles = {}
    
    for store in df[store_col].unique():
        store_data = df[df[store_col] == store]
        
        profiles[store] = {
            'avg_price': store_data[price_col].mean(),
            'price_std': store_data[price_col].std(),
            'total_sales': store_data[qty_col].sum(),
            'unique_products': store_data.iloc[:, 0].nunique(),  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –ø–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ - –∞—Ä—Ç–∏–∫—É–ª
            'avg_monthly_sales': store_data.groupby(store_data[date_col].dt.to_period('M'))[qty_col].sum().mean()
        }
    
    return profiles

def prepare_training_data(df, columns_mapping, store_profiles):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–æ–≤–∞—Ä–∞
    if columns_mapping.get('describe'):
        product_features = extract_features_from_text(df[columns_mapping['describe']])
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        product_features = pd.DataFrame({
            'gender': '–£–Ω–∏—Å–µ–∫—Å',
            'material': '–ü–ª–∞—Å—Ç–∏–∫',
            'shape': '–ü—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–µ',
            'is_polarized': 0,
            'has_uv': 0
        }, index=df.index)
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    train_data = df.copy()
    for col, values in product_features.items():
        train_data[col] = values
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π –º–∞–≥–∞–∑–∏–Ω–æ–≤
    train_data['store_avg_price'] = train_data[columns_mapping['magazin']].map(
        lambda x: store_profiles.get(x, {}).get('avg_price', 0)
    )
    train_data['store_volume'] = train_data[columns_mapping['magazin']].map(
        lambda x: store_profiles.get(x, {}).get('total_sales', 0)
    )
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    train_data['price_match'] = abs(train_data[columns_mapping['price']] - train_data['store_avg_price']) / train_data['store_avg_price']
    
    # –¶–µ–Ω–æ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
    train_data['price_segment'] = pd.cut(train_data[columns_mapping['price']], 
                                       bins=[0, 2000, 5000, float('inf')], 
                                       labels=['–≠–∫–æ–Ω–æ–º', '–°—Ä–µ–¥–Ω–∏–π', '–ü—Ä–µ–º–∏—É–º'])
    
    return train_data

@st.cache_resource
def train_model(train_data, target_col, feature_cols, cat_features):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ CatBoost"""
    X = train_data[feature_cols].copy()
    y = train_data[target_col]
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    for col in X.columns:
        if X[col].dtype == 'object':
            X[col] = X[col].fillna('Unknown')
        else:
            X[col] = X[col].fillna(X[col].median())
    
    model = CatBoostRegressor(
        iterations=100,
        depth=6,
        learning_rate=0.1,
        cat_features=cat_features,
        verbose=False,
        random_state=42
    )
    
    model.fit(X, y)
    return model

def predict_for_stores(model, new_product_features, stores, store_profiles, feature_cols):
    """–ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –≤—Å–µ—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤"""
    predictions = {}
    
    for store in stores:
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞
        store_profile = store_profiles.get(store, {})
        
        prediction_row = new_product_features.copy()
        prediction_row.update({
            'store_avg_price': store_profile.get('avg_price', 3000),
            'store_volume': store_profile.get('total_sales', 100),
            'price_match': abs(new_product_features['price'] - store_profile.get('avg_price', 3000)) / store_profile.get('avg_price', 3000),
            'magazin': store
        })
        
        # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        pred_df = pd.DataFrame([prediction_row])
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        for col in pred_df.columns:
            if col not in feature_cols:
                continue
            if pred_df[col].dtype == 'object':
                pred_df[col] = pred_df[col].fillna('Unknown')
            else:
                pred_df[col] = pred_df[col].fillna(0)
        
        try:
            pred = model.predict(pred_df[feature_cols])[0]
            predictions[store] = max(0, pred)  # –ù–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂
        except:
            predictions[store] = 0
    
    return predictions

# –û—Å–Ω–æ–≤–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
def main():
    st.title("üíñ –ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫ –ø–æ –ü—Ä–æ–¥–∞–∂–∞–º")
    st.markdown("*–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–¥–±–æ—Ä–∞ –º–∞–≥–∞–∑–∏–Ω–æ–≤ –¥–ª—è –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—á–∫–æ–≤*")
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
    with st.sidebar:
        st.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
        uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏", type=['xlsx', 'csv'])
        
        if uploaded_file:
            df, success_rows, error_rows = safe_read_file(uploaded_file)
            
            if df is not None:
                st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {success_rows} —Å—Ç—Ä–æ–∫")
                if error_rows > 0:
                    st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∏: {error_rows} —Å—Ç—Ä–æ–∫")
                
                # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä
                with st.expander("üëÄ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä"):
                    st.dataframe(df.head(3))
                
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
                st.header("üéØ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–ª–æ–Ω–æ–∫")
                columns = df.columns.tolist()
                
                columns_mapping = {
                    'magazin': st.selectbox("–ú–∞–≥–∞–∑–∏–Ω:", columns, 
                                          index=auto_detect_column(columns, ['magazin', '–º–∞–≥–∞–∑–∏–Ω', 'store'])),
                    'date': st.selectbox("–î–∞—Ç–∞:", columns,
                                       index=auto_detect_column(columns, ['date', '–¥–∞—Ç–∞', 'datasales'])),
                    'price': st.selectbox("–¶–µ–Ω–∞:", columns,
                                        index=auto_detect_column(columns, ['price', '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å'])),
                    'qty': st.selectbox("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ:", columns,
                                      index=auto_detect_column(columns, ['qty', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ', '–∫–æ–ª'])),
                    'describe': st.selectbox("–û–ø–∏—Å–∞–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):", 
                                           ["–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å"] + columns,
                                           index=0)
                }
                
                if columns_mapping['describe'] == "–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å":
                    columns_mapping['describe'] = None
    
    # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
    if uploaded_file and df is not None:
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π –º–∞–≥–∞–∑–∏–Ω–æ–≤
        with st.spinner("üîÑ –ê–Ω–∞–ª–∏–∑ –º–∞–≥–∞–∑–∏–Ω–æ–≤..."):
            store_profiles = create_store_profiles(df, columns_mapping['magazin'], 
                                                 columns_mapping['price'], columns_mapping['date'], 
                                                 columns_mapping['qty'])
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            train_data = prepare_training_data(df, columns_mapping, store_profiles)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏
            feature_cols = ['gender', 'material', 'shape', 'is_polarized', 'has_uv', 
                          'store_avg_price', 'store_volume', 'price_match', 'price_segment', 
                          columns_mapping['magazin']]
            cat_features = ['gender', 'material', 'shape', 'price_segment', columns_mapping['magazin']]
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model = train_model(train_data, columns_mapping['qty'], feature_cols, cat_features)
        
        st.success("üéØ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!")
        
        # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤–≤–æ–¥–∞ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        st.header("üÜï –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
        
        col1, col2 = st.columns(2)
        
        with col1:
            new_price = st.number_input("üí∞ –¶–µ–Ω–∞:", min_value=0, step=100, value=3000)
            new_gender = st.selectbox("üë§ –ü–æ–ª:", ["–ú—É–∂—Å–∫–∏–µ", "–ñ–µ–Ω—Å–∫–∏–µ", "–£–Ω–∏—Å–µ–∫—Å"])
            new_material = st.selectbox("üîß –ú–∞—Ç–µ—Ä–∏–∞–ª:", ["–ú–µ—Ç–∞–ª–ª", "–ü–ª–∞—Å—Ç–∏–∫", "–î–µ—Ä–µ–≤–æ"])
            new_shape = st.selectbox("üï∂Ô∏è –§–æ—Ä–º–∞:", ["–ê–≤–∏–∞—Ç–æ—Ä", "–í–∞–π—Ñ–∞—Ä–µ—Ä", "–ö—Ä—É–≥–ª—ã–µ", "–ü—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–µ", "–ö–æ—à–∞—á–∏–π –≥–ª–∞–∑"])
        
        with col2:
            new_polarized = st.checkbox("‚ö° –ü–æ–ª—è—Ä–∏–∑–∞—Ü–∏—è")
            new_uv = st.checkbox("üõ°Ô∏è UV –∑–∞—â–∏—Ç–∞")
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–Ω–æ–≤–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
            if new_price <= 2000:
                price_seg = "–≠–∫–æ–Ω–æ–º"
            elif new_price <= 5000:
                price_seg = "–°—Ä–µ–¥–Ω–∏–π"
            else:
                price_seg = "–ü—Ä–µ–º–∏—É–º"
            st.info(f"–¶–µ–Ω–æ–≤–æ–π —Å–µ–≥–º–µ–Ω—Ç: {price_seg}")
        
        # –ö–Ω–æ–ø–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        if st.button("üéØ –ü–û–î–û–ë–†–ê–¢–¨ –ú–ê–ì–ê–ó–ò–ù–´", type="primary"):
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏
            new_product = {
                'price': new_price,
                'gender': new_gender,
                'material': new_material,
                'shape': new_shape,
                'is_polarized': int(new_polarized),
                'has_uv': int(new_uv),
                'price_segment': price_seg
            }
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
            stores = df[columns_mapping['magazin']].unique()
            predictions = predict_for_stores(model, new_product, stores, store_profiles, feature_cols)
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            sorted_stores = sorted(predictions.items(), key=lambda x: x[1], reverse=True)
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            st.header("üèÜ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –º–∞–≥–∞–∑–∏–Ω–æ–≤")
            
            # –¢–û–ü-10
            st.subheader("‚úÖ –õ—É—á—à–∏–µ –º–∞–≥–∞–∑–∏–Ω—ã:")
            for i, (store, pred) in enumerate(sorted_stores[:10]):
                profile = store_profiles.get(store, {})
                compatibility = max(0, 100 - abs(new_price - profile.get('avg_price', new_price)) / new_price * 100)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric(f"#{i+1} {store}", f"{pred:.0f} —à—Ç/–º–µ—Å")
                with col2:
                    st.metric("–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å", f"{compatibility:.0f}%")
                with col3:
                    st.metric("–°—Ä–µ–¥–Ω–∏–π —á–µ–∫", f"{profile.get('avg_price', 0):.0f} ‚ÇΩ")
            
            # –ê–Ω—Ç–∏-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            st.subheader("‚ùå –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:")
            for store, pred in sorted_stores[-3:]:
                st.write(f"‚Ä¢ {store}: {pred:.0f} —à—Ç/–º–µ—Å (–Ω–∏–∑–∫–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)")
            
            # –ì—Ä–∞—Ñ–∏–∫
            fig = px.bar(x=[s[0] for s in sorted_stores[:15]], 
                        y=[s[1] for s in sorted_stores[:15]],
                        title="–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ –ø–æ –º–∞–≥–∞–∑–∏–Ω–∞–º",
                        labels={'x': '–ú–∞–≥–∞–∑–∏–Ω—ã', 'y': '–ü—Ä–æ–≥–Ω–æ–∑ (—à—Ç/–º–µ—Å)'})
            fig.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig, use_container_width=True)
    
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
        
        # –î–µ–º–æ –¥–∞–Ω–Ω—ã–µ
        st.header("üìä –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
        demo_data = pd.DataFrame({
            'Magazin': ['–û–ø—Ç–∏–∫–∞ –õ—é–∫—Å', '–°—Ç–∏–ª—å –¶–µ–Ω—Ç—Ä', '–ú–æ–¥–Ω—ã–µ –û—á–∫–∏'],
            'Datasales': ['2024-01-15', '2024-01-16', '2024-01-17'],
            'Art': ['RB001', 'OAK002', 'GUC003'],
            'Price': [15000, 8000, 25000],
            'Qty': [2, 5, 1],
            'Describe': ['Ray-Ban –∞–≤–∏–∞—Ç–æ—Ä—ã –º—É–∂—Å–∫–∏–µ –º–µ—Ç–∞–ª–ª –ø–æ–ª—è—Ä–∏–∑–∞—Ü–∏—è', 
                        'Oakley —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ —É–Ω–∏—Å–µ–∫—Å –ø–ª–∞—Å—Ç–∏–∫ UV400',
                        'Gucci –∂–µ–Ω—Å–∫–∏–µ –∫–æ—à–∞—á–∏–π –≥–ª–∞–∑ –ø—Ä–µ–º–∏—É–º']
        })
        st.dataframe(demo_data)

if __name__ == "__main__":
    main()
