import streamlit as st
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import optuna
import plotly.express as px
import re
import traceback

# ==============================================================================
# 1. –°–¢–†–£–ö–¢–£–†–ê –ò–ù–¢–ï–†–§–ï–ô–°–ê –ò –°–¢–ò–õ–ò
# ==============================================================================
st.set_page_config(page_title="–ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫", layout="wide", initial_sidebar_state="expanded")

st.markdown("""
<style>
/* –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–Ω –∏ —à—Ä–∏—Ñ—Ç—ã */
body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji"; }
.main { background-color: #f0f2f6; }
/* –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫–Ω–æ–ø–æ–∫ */
.stButton>button {
    border-radius: 8px; border: 2px solid #ff4b4b; color: #ff4b4b;
    background-color: transparent; font-weight: bold; transition: all 0.3s;
}
.stButton>button:hover {
    border-color: #ff4b4b; color: white; background-color: #ff4b4b;
}
/* –°—Ç–∏–ª—å –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π –∫–Ω–æ–ø–∫–∏ (type="primary") */
div[data-testid="stForm"] .stButton>button[kind="primary"] {
    border-color: #ff4b4b; color: white; background-color: #ff4b4b;
}
</style>
""", unsafe_allow_html=True)

# ==============================================================================
# 8. –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ß–ê–°–¢–¨: –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ==============================================================================

def auto_detect_column(columns, keywords, default_index=0):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º."""
    if not columns:
        return 0
    
    for keyword in keywords:
        for i, col in enumerate(columns):
            if keyword.lower() in str(col).lower():
                return i
    return min(default_index, len(columns) - 1) if columns else 0

def extract_features_from_description(descriptions_series):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è."""
    if descriptions_series.empty:
        return pd.DataFrame()
    
    features = pd.DataFrame(index=descriptions_series.index)
    descriptions_clean = descriptions_series.fillna('').astype(str).str.lower()
    
    extraction_map = {
        'brand_extracted': ['ray-ban', 'oakley', 'gucci', 'prada', 'polaroid'],
        'material_extracted': ['–º–µ—Ç–∞–ª–ª', '–ø–ª–∞—Å—Ç–∏–∫', '–¥–µ—Ä–µ–≤–æ', '–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π'],
        'shape_extracted': ['–∞–≤–∏–∞—Ç–æ—Ä', '–≤–∞–π—Ñ–∞—Ä–µ—Ä', '–∫—Ä—É–≥–ª—ã–µ', '–∫–æ—à–∞—á–∏–π –≥–ª–∞–∑']
    }
    
    for feature_name, keywords in extraction_map.items():
        results = []
        for desc in descriptions_clean:
            found = '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω'
            for keyword in keywords:
                if keyword in desc:
                    found = keyword
                    break
            results.append(found)
        features[feature_name] = results
    
    return features

@st.cache_data
def process_data_and_train(_df, column_map, feature_config):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ, –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏, –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å."""
    try:
        df = _df.copy()
        
        missing_columns = [f"`{v}` (–¥–ª—è `{k}`)" for k, v in column_map.items() if v and v not in df.columns]
        if missing_columns:
            return None, None, None, None, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö: {', '.join(missing_columns)}"

        all_features_df = pd.DataFrame(index=df.index)
        
        if feature_config['describe_col'] != "–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å":
            user_selected_describe_col = feature_config['describe_col']
            if user_selected_describe_col in df.columns and not df[user_selected_describe_col].empty:
                try:
                    extracted = extract_features_from_description(df[user_selected_describe_col])
                    if not extracted.empty:
                        all_features_df = pd.concat([all_features_df, extracted], axis=1)
                except Exception as e:
                    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è: {e}")

        for feature, source_col in feature_config['manual_features'].items():
            if source_col and source_col in df.columns and not df[source_col].empty:
                all_features_df[feature] = df[source_col].fillna('–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω').astype(str)

        df.rename(columns={v: k for k, v in column_map.items() if v}, inplace=True)
        required_cols = ['date', 'Art', 'Magazin', 'Qty', 'Price']
        if any(col not in df.columns for col in required_cols):
            return None, None, None, None, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è: `date`, `Art`, `Magazin`, `Qty`, `Price`"

        initial_len = len(df)
        df.dropna(subset=required_cols, inplace=True)
        if len(df) == 0:
            return None, None, None, None, "–í—Å–µ —Å—Ç—Ä–æ–∫–∏ –±—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã, —Ç–∞–∫ –∫–∞–∫ –≤ –Ω–∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª—è—Ö."

        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df.dropna(subset=['date'], inplace=True)
        if len(df) == 0:
            return None, None, None, None, "–í—Å–µ —Å—Ç—Ä–æ–∫–∏ —É–¥–∞–ª–µ–Ω—ã –∏–∑-–∑–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞—Ç—ã."

        df['Price'] = pd.to_numeric(df['Price'], errors='coerce').fillna(0)
        df['Qty'] = pd.to_numeric(df['Qty'], errors='coerce').fillna(0)
        df = df[(df['Price'] > 0) & (df['Qty'] > 0)]
        final_len = len(df)

        if final_len == 0:
            return None, None, None, None, "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ —Ü–µ–Ω—ã –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞."
        
        data_loss_percent = (initial_len - final_len) / initial_len * 100
        st.info(f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—á–∏—Å—Ç–∫–∏:** –ò—Å—Ö–æ–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {initial_len:,}. –°—Ç—Ä–æ–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {final_len:,}. –£–¥–∞–ª–µ–Ω–æ: {data_loss_percent:.1f}%")
        if data_loss_percent > 50:
            st.warning("‚ö†Ô∏è –£–¥–∞–ª–µ–Ω–æ –±–æ–ª–µ–µ 50% –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.")

        if not all_features_df.empty:
            df = pd.concat([df, all_features_df.reindex(df.index)], axis=1)
        
        df = df.sort_values(by=['Art', 'Magazin', 'date'])
        first_sale_dates = df.groupby(['Art', 'Magazin'])['date'].first().reset_index(name='first_sale_date')
        df_merged = pd.merge(df, first_sale_dates, on=['Art', 'Magazin'])
        df_30_days = df_merged[df_merged['date'] <= (df_merged['first_sale_date'] + pd.Timedelta(days=30))].copy()

        agg_logic = {'Qty': 'sum', 'Price': 'mean'}
        feature_cols = [col for col in all_features_df.columns if col in df_30_days.columns]
        for col in feature_cols:
            agg_logic[col] = 'first'
        
        df_agg = df_30_days.groupby(['Art', 'Magazin'], as_index=False).agg(agg_logic)
        df_agg.rename(columns={'Qty': 'Qty_30_days'}, inplace=True)

        if len(df_agg) < 10:
            return None, None, None, None, f"–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(df_agg)} –∑–∞–ø–∏—Å–µ–π. –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 10."

        target = 'Qty_30_days'
        cat_features_to_use = ['Magazin'] + feature_cols
        features_to_use = ['Price'] + cat_features_to_use
        
        X = df_agg[features_to_use].copy()
        y = df_agg[target]
        for col in cat_features_to_use:
            X[col] = X[col].fillna('–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω').astype('category')

        if len(X) < 5:
            return None, None, None, None, f"–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –≤—ã–±–æ—Ä–∫–∏: {len(X)}."

        test_size = min(0.2, max(0.1, 5.0 / len(X)))
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
        
        def objective(trial):
            params = {
                'iterations': 100,
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),
                'depth': trial.suggest_int('depth', 3, 6),
                'verbose': 0, 'random_seed': 42
            }
            model = CatBoostRegressor(**params, cat_features=cat_features_to_use)
            model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=10, use_best_model=True)
            return mean_absolute_error(y_test, model.predict(X_test))

        study = optuna.create_study(direction='minimize')
        study.optimize(objective, n_trials=10)
        
        final_model = CatBoostRegressor(**study.best_params, iterations=200, verbose=0, random_seed=42, cat_features=cat_features_to_use)
        final_model.fit(X, y)
        
        y_pred = final_model.predict(X_test)
        metrics = {'MAE': mean_absolute_error(y_test, y_pred), 'R2': max(0, r2_score(y_test, y_pred))}
        
        unique_values_for_prediction = {col: X[col].unique().tolist() for col in cat_features_to_use}

        return final_model, features_to_use, metrics, unique_values_for_prediction, None
        
    except Exception as e:
        error_details = traceback.format_exc()
        return None, None, None, None, f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}\n\n–î–µ—Ç–∞–ª–∏:\n{error_details}"

# ==============================================================================
# –û–°–ù–û–í–ù–û–ô –ö–û–î –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
# ==============================================================================

st.title("üíñ –ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫ –ø–æ –ü—Ä–æ–¥–∞–∂–∞–º")

if 'step' not in st.session_state:
    st.session_state.step = 1

with st.sidebar:
    st.header("1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª Excel –∏–ª–∏ CSV", type=["csv", "xlsx", "xls"], key="file_uploader")

    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'):
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                except UnicodeDecodeError:
                    uploaded_file.seek(0)
                    df = pd.read_csv(uploaded_file, encoding='cp1251')
            else:
                df = pd.read_excel(uploaded_file, engine='openpyxl')
            
            if df.empty:
                st.error("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π!")
                st.stop()
            
            # ===== –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ó–î–ï–°–¨ =====
            # –°—Ç–∞—Ä—ã–π –∫–æ–¥: df.columns = df.columns.astype(str).str.strip()
            # –ù–æ–≤—ã–π, –Ω–∞–¥–µ–∂–Ω—ã–π –∫–æ–¥:
            df.columns = [str(col).strip() for col in df.columns]
            # ==============================

            st.session_state.df_raw = df
            st.session_state.step = 1
            
            st.success(f"üìä –§–∞–π–ª '{uploaded_file.name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
            col1, col2 = st.columns(2)
            col1.metric("–°—Ç—Ä–æ–∫", f"{len(df):,}")
            col2.metric("–ö–æ–ª–æ–Ω–æ–∫", f"{len(df.columns):,}")
            
            with st.expander("üëÄ –ü—Ä–µ–≤—å—é –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö"):
                st.dataframe(df.head(10))
                st.write("**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—é –∫–æ–ª–æ–Ω–æ–∫:**")
                col_stats = pd.DataFrame({
                    '–ó–∞–ø–æ–ª–Ω–µ–Ω–æ, %': (df.count() / len(df) * 100).round(1),
                    '–ü—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π': df.isnull().sum(),
                })
                st.dataframe(col_stats, use_container_width=True)

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            st.stop()

if 'df_raw' in st.session_state:
    df_raw = st.session_state.df_raw
    available_columns = [""] + df_raw.columns.tolist()

    st.header("2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞")
    with st.form("column_mapping_form"):
        st.subheader("üéØ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")
        c1, c2 = st.columns(2)
        with c1:
            col_magazin = st.selectbox("–ú–∞–≥–∞–∑–∏–Ω:", available_columns, index=auto_detect_column(available_columns, ['magazin', '–º–∞–≥–∞–∑–∏–Ω']))
            col_art = st.selectbox("–ê—Ä—Ç–∏–∫—É–ª:", available_columns, index=auto_detect_column(available_columns, ['art', '–∞—Ä—Ç–∏–∫—É–ª'], 1))
            col_qty = st.selectbox("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ:", available_columns, index=auto_detect_column(available_columns, ['qty', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ'], 2))
        with c2:
            col_date = st.selectbox("–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏:", available_columns, index=auto_detect_column(available_columns, ['datasales', '–¥–∞—Ç–∞'], 3))
            col_price = st.selectbox("–¶–µ–Ω–∞:", available_columns, index=auto_detect_column(available_columns, ['price', '—Ü–µ–Ω–∞'], 4))
            col_describe = st.selectbox("–û–ø–∏—Å–∞–Ω–∏–µ (–¥–ª—è –∞–≤—Ç–æ-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤):", available_columns + ["–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å"], index=auto_detect_column(available_columns, ['describe', '–æ–ø–∏—Å–∞–Ω–∏–µ'], 5))

        st.subheader("‚ú® –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–≤–∞—Ä–∞")
        other_feature_cols = st.multiselect(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫–∏ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ (–ë—Ä–µ–Ω–¥, –¶–≤–µ—Ç, –ü–æ–ª –∏ —Ç.–¥.):",
            [c for c in df_raw.columns if c not in [col_magazin, col_art, col_qty, col_date, col_price, col_describe] and c != ""]
        )
        
        submitted = st.form_submit_button("‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –∏ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary", use_container_width=True)

    if submitted:
        if not all([col_magazin, col_art, col_qty, col_date, col_price]):
            st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏!")
        else:
            column_map = {'Magazin': col_magazin, 'Art': col_art, 'date': col_date, 'Qty': col_qty, 'Price': col_price}
            feature_config = {'describe_col': col_describe, 'manual_features': {col: col for col in other_feature_cols}}
            
            with st.spinner("–ú–∞–≥–∏—è –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ... –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—É—á–∞—é –º–æ–¥–µ–ª—å..."):
                model, features, metrics, unique_vals, error_msg = process_data_and_train(df_raw, column_map, feature_config)

            if error_msg:
                st.error(f"**–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞:**\n\n{error_msg}")
                st.session_state.step = 1
            else:
                st.session_state.model = model
                st.session_state.features = features
                st.session_state.metrics = metrics
                st.session_state.unique_values_for_prediction = unique_vals
                st.session_state.feature_config = feature_config
                st.session_state.step = 2
                st.success("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Ñ–æ—Ä–º–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∏–∂–µ. üëá")
                st.rerun()

if st.session_state.step == 2:
    st.header("3. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
    metrics = st.session_state.metrics
    c1, c2 = st.columns(2)
    c1.metric("–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ (MAE)", f"{metrics['MAE']:.2f} —à—Ç.", help="–í —Å—Ä–µ–¥–Ω–µ–º –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è –Ω–∞ —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –µ–¥–∏–Ω–∏—Ü —Ç–æ–≤–∞—Ä–∞.")
    c2.metric("–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (R¬≤)", f"{metrics['R2']:.1%}", help="–ù–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å –æ–±—ä—è—Å–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ (—á–µ–º –±–ª–∏–∂–µ –∫ 100%, —Ç–µ–º –ª—É—á—à–µ).")

    try:
        feature_importance_df = pd.DataFrame({
            '–ü—Ä–∏–∑–Ω–∞–∫': st.session_state.features,
            '–í–∞–∂–Ω–æ—Å—Ç—å': st.session_state.model.get_feature_importance()
        }).sort_values('–í–∞–∂–Ω–æ—Å—Ç—å', ascending=False)
        fig = px.bar(feature_importance_df, x='–í–∞–∂–Ω–æ—Å—Ç—å', y='–ü—Ä–∏–∑–Ω–∞–∫', orientation='h', title='–ù–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –ø—Ä–æ–¥–∞–∂')
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")

    st.header("4. –°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑")
    st.info("–í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ–≥–æ —Ç–æ–≤–∞—Ä–∞, —á—Ç–æ–±—ã —Å–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ –ø—Ä–æ–¥–∞–∂–∏ –∑–∞ –ø–µ—Ä–≤—ã–µ 30 –¥–Ω–µ–π.")
    
    unique_vals = st.session_state.unique_values_for_prediction
    
    with st.form("prediction_form"):
        prediction_data = {}
        cols = st.columns(2)
        
        col_idx = 0
        for feature in st.session_state.features:
            current_col = cols[col_idx % 2]
            with current_col:
                if feature == 'Price':
                    prediction_data[feature] = st.number_input("–¶–µ–Ω–∞ —Ç–æ–≤–∞—Ä–∞", min_value=0.0, step=100.0, value=1000.0)
                elif feature in unique_vals:
                    options = sorted(unique_vals[feature])
                    prediction_data[feature] = st.selectbox(f"–ü—Ä–∏–∑–Ω–∞–∫: {feature}", options=options, index=0)

        predict_button = st.form_submit_button("üîÆ –°–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–¥–∞–∂–∏", type="primary", use_container_width=True)

    if predict_button:
        try:
            input_df = pd.DataFrame([prediction_data])
            for col in input_df.columns:
                if col in st.session_state.model.get_cat_feature_indices():
                    input_df[col] = input_df[col].astype('category')

            prediction = st.session_state.model.predict(input_df)
            predicted_qty = int(round(prediction[0]))
            
            st.success(f"### üìà –ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂: **~{predicted_qty} —à—Ç.**")
            st.caption("–≠—Ç–æ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–∞, –∫–æ—Ç–æ—Ä–æ–µ –±—É–¥–µ—Ç –ø—Ä–æ–¥–∞–Ω–æ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –º–∞–≥–∞–∑–∏–Ω–µ –∑–∞ –ø–µ—Ä–≤—ã–µ 30 –¥–Ω–µ–π.")

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
