import streamlit as st
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import optuna

# --- –°–¢–ò–õ–ò–ó–ê–¶–ò–Ø –ò–ù–¢–ï–†–§–ï–ô–°–ê ---
st.set_page_config(page_title="–ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫", layout="wide", initial_sidebar_state="collapsed")

st.markdown("""
<style>
/* –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–Ω –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è */
.main { background-color: #fce4ec; }
h1 { font-family: 'Comic Sans MS', cursive, sans-serif; color: #e91e63; text-align: center; text-shadow: 2px 2px 4px #f8bbd0; }
h2, h3 { font-family: 'Comic Sans MS', cursive, sans-serif; color: #ad1457; }
.stButton>button {
    color: white; background-image: linear-gradient(to right, #f06292, #e91e63); border-radius: 25px;
    border: 2px solid #ad1457; padding: 12px 28px; font-weight: bold; font-size: 18px;
    box-shadow: 0 4px 15px 0 rgba(233, 30, 99, 0.4); transition: all 0.3s ease 0s;
}
.stButton>button:hover { background-position: right center; box-shadow: 0 4px 15px 0 rgba(233, 30, 99, 0.75); }
.stExpander { border: 2px solid #f8bbd0; border-radius: 10px; background-color: #fff1f8; }
</style>
""", unsafe_allow_html=True)

st.title("üíñ –ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫ –ø–æ –ü—Ä–æ–¥–∞–∂–∞–º üíñ")

# --- –ë–õ–û–ö –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–• –§–£–ù–ö–¶–ò–ô ---

def suggest_date_column(df):
    """–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç, –∫–∞–∫–∞—è –∫–æ–ª–æ–Ω–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –¥–∞—Ç–æ–π, –Ω–æ –Ω–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –µ–µ."""
    potential_date_cols = [
        'Datasales', 'datasales', 'date', 'Date', 'data', '–î–∞—Ç–∞', '–¥–∞—Ç–∞_–ø—Ä–æ–¥–∞–∂–∏', 'timestamp'
    ]
    for col_name in potential_date_cols:
        if col_name in df.columns:
            return col_name
    # –ï—Å–ª–∏ –ø–æ –∏–º–µ–Ω–∏ –Ω–µ –Ω–∞—à–ª–∏, –∏—â–µ–º –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É (–Ω–æ –º–µ–Ω–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ)
    for col_name in df.select_dtypes(include=['object']).columns:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ö–æ—Ç—è –±—ã —á–∞—Å—Ç—å —Å—Ç—Ä–æ–∫
            if pd.to_datetime(df[col_name], errors='coerce', infer_datetime_format=True).notna().sum() > 0:
                 # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –µ—Å—Ç—å –Ω–∞–º–µ–∫ –Ω–∞ –¥–∞—Ç—É
                if any(substr in col_name.lower() for substr in ['date', '–¥–∞—Ç–∞', 'day', '–¥–µ–Ω—å']):
                    return col_name
        except Exception:
            continue
    return None

def display_data_stats(total_rows, clean_rows, bad_date_rows, df_agg, date_col_name):
    with st.expander("üìä –°–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ...", expanded=True):
        col1, col2, col3 = st.columns(3)
        col1.metric("–°—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ üíÖ", f"{total_rows}")
        col2.metric("–°—Ç—Ä–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ üíé", f"{clean_rows}", help="–°—Ç—Ä–æ–∫–∏ —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ 'Qty', 'Art', 'Magazin' –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –¥–∞—Ç–æ–π.")
        col3.metric("–£–¥–∞–ª–µ–Ω–æ –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫ üóëÔ∏è", f"{(total_rows - clean_rows)}", help=f"–í–∫–ª—é—á–∞—è {bad_date_rows} —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º –¥–∞—Ç—ã –≤ –∫–æ–ª–æ–Ω–∫–µ '{date_col_name}'.")
        st.success(f"""
        - **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—á–∫–æ–≤:** {df_agg['Art'].nunique()} üï∂Ô∏è
        - **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—É—Ç–∏–∫–æ–≤:** {df_agg['Magazin'].nunique()} üè¨
        - **–ü–µ—Ä–∏–æ–¥ –ø—Ä–æ–¥–∞–∂:** —Å {df_agg['first_sale_date'].min().strftime('%d.%m.%Y')} –ø–æ {df_agg['first_sale_date'].max().strftime('%d.%m.%Y')} üóìÔ∏è
        """)

@st.cache_data
def process_and_aggregate(df, date_col_name):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –∫—ç—à–∏—Ä—É–µ—Ç—Å—è."""
    initial_rows = len(df)
    
    # 1. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç—ã –∏ —É–¥–∞–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫
    df[date_col_name] = pd.to_datetime(df[date_col_name], errors='coerce')
    rows_before_date_drop = len(df)
    df.dropna(subset=[date_col_name], inplace=True)
    rows_after_date_drop = len(df)
    bad_date_rows = rows_before_date_drop - rows_after_date_drop

    # 2. –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
    crucial_cols = ['Qty', 'Art', 'Magazin']
    df_clean = df.dropna(subset=crucial_cols).copy()
    
    # 3. –ê–≥—Ä–µ–≥–∞—Ü–∏—è
    df_clean = df_clean.sort_values(by=['Art', 'Magazin', date_col_name])
    series_of_first_dates = df_clean.groupby(['Art', 'Magazin'])[date_col_name].first()
    first_sale_dates = series_of_first_dates.reset_index(name='first_sale_date')
    df_merged = pd.merge(df_clean, first_sale_dates, on=['Art', 'Magazin'])
    df_30_days = df_merged[df_merged[date_col_name] <= (df_merged['first_sale_date'] + pd.Timedelta(days=30))].copy()
    agg_logic = {
        'Qty': 'sum', 'Sum': 'sum', 'Price': 'mean', 'Model': 'first', 'brand': 'first',
        'Segment': 'first', 'color': 'first', 'formaoprav': 'first', 'Sex': 'first', 'Metal-Plastic': 'first',
        'first_sale_date': 'first' # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    }
    df_agg = df_30_days.groupby(['Art', 'Magazin'], as_index=False).agg(agg_logic)
    df_agg.rename(columns={'Qty': 'Qty_30_days'}, inplace=True)

    stats = {
        "total_rows": initial_rows, 
        "clean_rows": len(df_agg), 
        "bad_date_rows": bad_date_rows
    }
    return df_agg, stats

@st.cache_resource
def train_model_with_optuna(_df_agg):
    # (–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    target, cat_features = 'Qty_30_days', ['Magazin', 'brand', 'Segment', 'color', 'formaoprav', 'Sex', 'Metal-Plastic']
    df_processed = _df_agg.drop(columns=['Sum', 'Art', 'Model', 'first_sale_date'], errors='ignore')
    features = [col for col in df_processed.columns if col != target]
    for col in cat_features:
        if col in df_processed.columns: df_processed[col] = df_processed[col].astype(str)
    X, y = df_processed[features], df_processed[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
    with st.spinner("üîÆ –ü–æ–¥–±–∏—Ä–∞—é –ª—É—á—à–∏–µ –≤–æ–ª—à–µ–±–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏..."):
        optuna.logging.set_verbosity(optuna.logging.WARNING)
        study = optuna.create_study(direction='minimize')
        study.optimize(lambda trial: mean_absolute_error(y_test, CatBoostRegressor(
            iterations=1000, learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),
            depth=trial.suggest_int('depth', 4, 10), verbose=0, random_seed=42
        ).fit(X_train, y_train, cat_features=cat_features, eval_set=(X_test, y_test), early_stopping_rounds=50, use_best_model=True).predict(X_test)), n_trials=30)
    st.success(f"–í–æ–ª—à–µ–±—Å—Ç–≤–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ! üí´ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {study.best_params}")
    final_model = CatBoostRegressor(**study.best_params, iterations=1500, verbose=0, random_seed=42).fit(X, y, cat_features=cat_features)
    test_preds = final_model.predict(X_test)
    return final_model, features, {'MAE': mean_absolute_error(y_test, test_preds), 'R2': r2_score(y_test, test_preds)}

# --- –û–°–ù–û–í–ù–û–ô –ë–õ–û–ö STREAMLIT ---

dataset_file = st.file_uploader("üíñ –ó–∞–≥—Ä—É–∑–∏ —Å–≤–æ–π —Ñ–∞–π–ª —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏ (.xlsx, .xls, .csv)", type=["csv", "xlsx", "xls"])

if dataset_file:
    try:
        if dataset_file.name.endswith('.csv'):
            df_raw = pd.read_csv(dataset_file)
        else:
            df_raw = pd.read_excel(dataset_file, engine='openpyxl')
    except Exception as e:
        st.error(f"–ù–µ –º–æ–≥—É –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª, –¥–æ—Ä–æ–≥–∞—è! –û—à–∏–±–∫–∞: {e}")
        st.stop()
    
    # --- –ù–û–í–´–ô –ë–õ–û–ö: –†–£–ß–ù–û–ô –í–´–ë–û–† –ö–û–õ–û–ù–ö–ò –° –î–ê–¢–û–ô ---
    st.subheader("–®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö üßê")
    suggested_col = suggest_date_column(df_raw)
    all_columns = df_raw.columns.tolist()
    
    if suggested_col and suggested_col in all_columns:
        default_index = all_columns.index(suggested_col)
    else:
        default_index = 0
        
    date_col_name = st.selectbox(
        "üéÄ –Ø –¥—É–º–∞—é, –∫–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π —ç—Ç–æ...",
        options=all_columns,
        index=default_index,
        help="–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏ –∫–æ–ª–æ–Ω–∫—É, –≥–¥–µ —É–∫–∞–∑–∞–Ω–∞ –¥–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏. –Ø –ø–æ—Å—Ç–∞—Ä–∞–ª–∞—Å—å —É–≥–∞–¥–∞—Ç—å —Å–∞–º–∞!"
    )
    
    df_agg, stats = process_and_aggregate(df_raw, date_col_name)
    display_data_stats(stats['total_rows'], stats['clean_rows'], stats['bad_date_rows'], df_agg, date_col_name)

    if df_agg is not None and not df_agg.empty:
        st.subheader("–®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ üßô‚Äç‚ôÄÔ∏è")
        model, features, metrics = train_model_with_optuna(df_agg)
        if model:
            # (–û—Å—Ç–∞–ª—å–Ω–∞—è —á–∞—Å—Ç—å –∫–æ–¥–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
            st.header("üìä –û—Ü–µ–Ω–∫–∞ –º–æ–µ–π —Ä–∞–±–æ—Ç—ã")
            col1, col2 = st.columns(2)
            col1.metric("–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ (MAE)", f"{metrics['MAE']:.2f} —à—Ç.", "+/- —Å—Ç–æ–ª—å–∫–æ —è –º–æ–≥—É –æ—à–∏–±–∏—Ç—å—Å—è")
            col2.metric("–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (R¬≤)", f"{metrics['R2']:.2%}", "—á–µ–º –±–ª–∏–∂–µ –∫ 100%, —Ç–µ–º –ª—É—á—à–µ!")

            st.header("‚úçÔ∏è –û–ø–∏—à–∏ —Å–≤–æ—é –Ω–æ–≤—É—é –±–ª–µ—Å—Ç—è—â—É—é –º–æ–¥–µ–ª—å –æ—á–∫–æ–≤")
            with st.form("product_form"):
                col1, col2 = st.columns(2)
                with col1:
                    brand = st.text_input("–ë—Ä–µ–Ω–¥ üëë", help="–ù–∞–ø—Ä–∏–º–µ—Ä, Miu Miu")
                    forma = st.text_input("–§–æ—Ä–º–∞ –æ–ø—Ä–∞–≤—ã üëì", help="–ù–∞–ø—Ä–∏–º–µ—Ä, –ö–æ—à–∞—á–∏–π –≥–ª–∞–∑")
                    sex = st.selectbox("–î–ª—è –∫–æ–≥–æ? üë†", df_agg['Sex'].unique())
                    price = st.number_input("–¶–µ–Ω–∞ üí∞", min_value=0.0, step=100.0, format="%.2f")
                with col2:
                    segment = st.selectbox("–°–µ–≥–º–µ–Ω—Ç üíÖ", df_agg['Segment'].unique())
                    color = st.text_input("–¶–≤–µ—Ç üåà", help="–ù–∞–ø—Ä–∏–º–µ—Ä, –†–æ–∑–æ–≤—ã–π")
                    material = st.selectbox("–ú–∞—Ç–µ—Ä–∏–∞–ª ‚ú®", df_agg['Metal-Plastic'].unique())
                submitted = st.form_submit_button("–ù–∞–π—Ç–∏ –ª—É—á—à–∏–µ –±—É—Ç–∏–∫–∏! üöÄ")

            if submitted:
                magaziny = df_agg['Magazin'].unique()
                new_product_data = {'brand': brand, 'Segment': segment, 'color': color, 'formaoprav': forma,
                                    'Sex': sex, 'Metal-Plastic': material, 'Price': price}
                recs_df = pd.DataFrame([dict(item, Magazin=mag) for mag in magaziny for item in [new_product_data]])[features]
                recs_df['Pred_Qty_30_days'] = np.maximum(0, model.predict(recs_df).round(0))
                max_pred = recs_df['Pred_Qty_30_days'].max()
                recs_df['Rating_%'] = (recs_df['Pred_Qty_30_days'] / max_pred * 100).round(0) if max_pred > 0 else 0
                
                top_magaziny = recs_df.sort_values(by='Pred_Qty_30_days', ascending=False).rename(columns={
                    'Magazin': '–ë—É—Ç–∏–∫', 'Pred_Qty_30_days': '–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)', 'Rating_%': '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)'
                })

                st.subheader("üéâ –í–æ—Ç –ª—É—á—à–∏–µ –º–µ—Å—Ç–∞ –¥–ª—è —Ç–≤–æ–µ–π –Ω–æ–≤–∏–Ω–∫–∏! üéâ")
                st.dataframe(top_magaziny[['–ë—É—Ç–∏–∫', '–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)', '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)']].style.highlight_max(
                    subset=['–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)'], color='#f8bbd0', axis=0
                ).format({'–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)': '{:.0f}', '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)': '{:.0f}%'}), use_container_width=True)
else:
    st.info("üíã –ü—Ä–∏–≤–µ—Ç! –ó–∞–≥—Ä—É–∑–∏ —Ñ–∞–π–ª–∏–∫, –∏ —è –ø–æ–º–æ–≥—É —Ç–µ–±–µ —Å—Ç–∞—Ç—å –∑–≤–µ–∑–¥–æ–π –ø—Ä–æ–¥–∞–∂!")
