import streamlit as st
import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import optuna

# --- –°–¢–ò–õ–ò–ó–ê–¶–ò–Ø –ò–ù–¢–ï–†–§–ï–ô–°–ê ---
st.set_page_config(page_title="–ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫", layout="wide", initial_sidebar_state="collapsed")

st.markdown("""
<style>
/* –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–æ–Ω –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è */
.main { background-color: #fce4ec; }
h1 { font-family: 'Comic Sans MS', cursive, sans-serif; color: #e91e63; text-align: center; text-shadow: 2px 2px 4px #f8bbd0; }
h2, h3 { font-family: 'Comic Sans MS', cursive, sans-serif; color: #ad1457; }
.stButton>button {
    color: white; background-image: linear-gradient(to right, #f06292, #e91e63); border-radius: 25px;
    border: 2px solid #ad1457; padding: 12px 28px; font-weight: bold; font-size: 18px;
    box-shadow: 0 4px 15px 0 rgba(233, 30, 99, 0.4); transition: all 0.3s ease 0s;
}
.stButton>button:hover { background-position: right center; box-shadow: 0 4px 15px 0 rgba(233, 30, 99, 0.75); }
.stExpander { border: 2px solid #f8bbd0; border-radius: 10px; background-color: #fff1f8; }
</style>
""", unsafe_allow_html=True)

st.title("üíñ –ú–æ–¥–Ω—ã–π –°–æ–≤–µ—Ç–Ω–∏–∫ –ø–æ –ü—Ä–æ–¥–∞–∂–∞–º üíñ")

# --- –ë–õ–û–ö –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–• –§–£–ù–ö–¶–ò–ô ---

@st.cache_data
def process_and_aggregate(_df, column_map):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –∫—ç—à–∏—Ä—É–µ—Ç—Å—è."""
    df = _df.copy()
    
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    internal_map = {v: k for k, v in column_map.items()}
    df.rename(columns=internal_map, inplace=True)
    
    initial_rows = len(df)
    
    # 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    bad_date_rows = df['date'].isna().sum()
    df.dropna(subset=['date'], inplace=True)

    # 2. –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
    crucial_cols = ['Qty', 'Art', 'Magazin', 'Price']
    df.dropna(subset=crucial_cols, inplace=True)
    
    # 3. –ê–≥—Ä–µ–≥–∞—Ü–∏—è
    df = df.sort_values(by=['Art', 'Magazin', 'date'])
    series_of_first_dates = df.groupby(['Art', 'Magazin'])['date'].first()
    first_sale_dates = series_of_first_dates.reset_index(name='first_sale_date')
    df_merged = pd.merge(df, first_sale_dates, on=['Art', 'Magazin'])
    df_30_days = df_merged[df_merged['date'] <= (df_merged['first_sale_date'] + pd.Timedelta(days=30))].copy()

    agg_logic = {'Qty': 'sum', 'Price': 'mean'}
    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ–º –∞–≥—Ä–µ–≥–∞—Ü–∏—é –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    for cat_col in column_map['categorical_features']:
        agg_logic[cat_col] = 'first'
    
    df_agg = df_30_days.groupby(['Art', 'Magazin'], as_index=False).agg(agg_logic)
    df_agg.rename(columns={'Qty': 'Qty_30_days'}, inplace=True)
    
    stats = {
        "total_rows": initial_rows, 
        "final_rows": len(df_agg), 
        "bad_date_rows": bad_date_rows
    }
    return df_agg, stats

@st.cache_resource
def train_model_with_optuna(_df_agg, cat_features):
    target = 'Qty_30_days'
    # 'Art' –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫
    features = ['Magazin', 'Price'] + cat_features
    df_processed = _df_agg[features + [target]]
    
    for col in cat_features + ['Magazin']:
        df_processed[col] = df_processed[col].astype(str)

    X, y = df_processed[features], df_processed[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

    with st.spinner("üîÆ –ü–æ–¥–±–∏—Ä–∞—é –ª—É—á—à–∏–µ –≤–æ–ª—à–µ–±–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏..."):
        optuna.logging.set_verbosity(optuna.logging.WARNING)
        study = optuna.create_study(direction='minimize')
        study.optimize(lambda trial: mean_absolute_error(y_test, CatBoostRegressor(
            iterations=1000, learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),
            depth=trial.suggest_int('depth', 4, 10), verbose=0, random_seed=42
        ).fit(X_train, y_train, cat_features=cat_features + ['Magazin'], eval_set=(X_test, y_test), early_stopping_rounds=50, use_best_model=True).predict(X_test)), n_trials=30)
    
    st.success(f"–í–æ–ª—à–µ–±—Å—Ç–≤–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ! üí´ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {study.best_params}")
    final_model = CatBoostRegressor(**study.best_params, iterations=1500, verbose=0, random_seed=42).fit(X, y, cat_features=cat_features + ['Magazin'])
    test_preds = final_model.predict(X_test)
    return final_model, features, {'MAE': mean_absolute_error(y_test, test_preds), 'R2': r2_score(y_test, test_preds)}

# --- –û–°–ù–û–í–ù–û–ô –ë–õ–û–ö STREAMLIT ---

if 'processed' not in st.session_state:
    st.session_state.processed = False

dataset_file = st.file_uploader("üíñ –ó–∞–≥—Ä—É–∑–∏ —Å–≤–æ–π —Ñ–∞–π–ª —Å –ø—Ä–æ–¥–∞–∂–∞–º–∏ (.xlsx, .xls, .csv)", type=["csv", "xlsx", "xls"])

if dataset_file:
    try:
        if dataset_file.name.endswith('.csv'):
            df_raw = pd.read_csv(dataset_file)
        else:
            df_raw = pd.read_excel(dataset_file, engine='openpyxl')
        st.session_state.df_raw = df_raw
    except Exception as e:
        st.error(f"–ù–µ –º–æ–≥—É –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª, –¥–æ—Ä–æ–≥–∞—è! –û—à–∏–±–∫–∞: {e}")
        st.stop()
    
    st.subheader("–®–∞–≥ 1: –ü–æ–º–æ–≥–∏ –º–Ω–µ –ø–æ–Ω—è—Ç—å —Ç–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ üßê")
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏, –∫–∞–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Ç–≤–æ–µ–º —Ñ–∞–π–ª–µ –∑–∞ —á—Ç–æ –æ—Ç–≤–µ—á–∞—é—Ç. –≠—Ç–æ –æ—á–µ–Ω—å –≤–∞–∂–Ω–æ! üôè")
    
    all_columns = st.session_state.df_raw.columns.tolist()
    
    with st.form("mapping_form"):
        col1, col2 = st.columns(2)
        with col1:
            art_col = st.selectbox("–ê—Ä—Ç–∏–∫—É–ª —Ç–æ–≤–∞—Ä–∞ (ID)", all_columns, index=0)
            magazin_col = st.selectbox("–ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞", all_columns, index=1)
            date_col = st.selectbox("–î–∞—Ç–∞ –ø—Ä–æ–¥–∞–∂–∏", all_columns, index=2)
        with col2:
            qty_col = st.selectbox("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥–∞–Ω–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ (—à—Ç.)", all_columns, index=3)
            price_col = st.selectbox("–¶–µ–Ω–∞ —Ç–æ–≤–∞—Ä–∞", all_columns, index=4)
        
        available_features = [c for c in all_columns if c not in [art_col, magazin_col, date_col, qty_col, price_col]]
        cat_features_selected = st.multiselect(
            "–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ç–æ–≤–∞—Ä–∞ (–≤—ã–±–µ—Ä–∏ –≤—Å–µ, —á—Ç–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–æ–≤–∞—Ä)",
            available_features,
            help="–í—ã–±–µ—Ä–∏ –∫–æ–ª–æ–Ω–∫–∏ –≤—Ä–æ–¥–µ '–ë—Ä–µ–Ω–¥', '–¶–≤–µ—Ç', '–ú–∞—Ç–µ—Ä–∏–∞–ª', '–°–µ–≥–º–µ–Ω—Ç' –∏ —Ç.–¥."
        )
        
        submitted_mapping = st.form_submit_button("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å üöÄ")

    if submitted_mapping:
        column_map = {
            'Art': art_col, 'Magazin': magazin_col, 'date': date_col,
            'Qty': qty_col, 'Price': price_col,
            'categorical_features': cat_features_selected
        }
        st.session_state.column_map = column_map
        
        df_agg, stats = process_and_aggregate(st.session_state.df_raw, column_map)
        
        with st.expander("üìä –°–º–æ—Ç—Ä–∏–º –Ω–∞ —Ç–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ...", expanded=True):
            st.metric("–°—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ üíÖ", f"{stats['total_rows']}")
            st.metric("–°—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ üíé", f"{stats['final_rows']}")
            st.metric("–°—Ç—Ä–æ–∫ —Å –ø–ª–æ—Ö–æ–π –¥–∞—Ç–æ–π üóëÔ∏è", f"{stats['bad_date_rows']}")
        
        st.session_state.df_agg = df_agg
        
        model, features, metrics = train_model_with_optuna(df_agg, cat_features_selected)
        st.session_state.model = model
        st.session_state.features = features
        st.session_state.metrics = metrics
        st.session_state.processed = True
        st.rerun()

if st.session_state.processed:
    st.subheader("–®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ üßô‚Äç‚ôÄÔ∏è")
    st.header("üìä –û—Ü–µ–Ω–∫–∞ –º–æ–µ–π —Ä–∞–±–æ—Ç—ã")
    metrics = st.session_state.metrics
    col1, col2 = st.columns(2)
    col1.metric("–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ (MAE)", f"{metrics['MAE']:.2f} —à—Ç.", "+/- —Å—Ç–æ–ª—å–∫–æ —è –º–æ–≥—É –æ—à–∏–±–∏—Ç—å—Å—è")
    col2.metric("–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (R¬≤)", f"{metrics['R2']:.2%}", "—á–µ–º –±–ª–∏–∂–µ –∫ 100%, —Ç–µ–º –ª—É—á—à–µ!")

    st.header("‚úçÔ∏è –û–ø–∏—à–∏ —Å–≤–æ—é –Ω–æ–≤—É—é –±–ª–µ—Å—Ç—è—â—É—é –º–æ–¥–µ–ª—å –æ—á–∫–æ–≤")
    with st.form("product_form"):
        new_product_data = {}
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ–º –ø–æ–ª—è –¥–ª—è –≤–≤–æ–¥–∞
        for feature in st.session_state.column_map['categorical_features']:
            unique_vals = st.session_state.df_agg[feature].dropna().unique().tolist()
            new_product_data[feature] = st.selectbox(f"{feature} ‚ú®", unique_vals)
        
        new_product_data['Price'] = st.number_input("–¶–µ–Ω–∞ üí∞", min_value=0.0, step=100.0, format="%.2f")
        
        submitted_prediction = st.form_submit_button("–ù–∞–π—Ç–∏ –ª—É—á—à–∏–µ –±—É—Ç–∏–∫–∏! üöÄ")

    if submitted_prediction:
        df_agg = st.session_state.df_agg
        model = st.session_state.model
        features = st.session_state.features
        
        magaziny = df_agg['Magazin'].unique()
        
        recs_list = []
        for magazin in magaziny:
            row = new_product_data.copy()
            row['Magazin'] = magazin
            recs_list.append(row)

        recs_df = pd.DataFrame(recs_list)[features]
        recs_df['Pred_Qty_30_days'] = np.maximum(0, model.predict(recs_df).round(0))
        max_pred = recs_df['Pred_Qty_30_days'].max()
        recs_df['Rating_%'] = (recs_df['Pred_Qty_30_days'] / max_pred * 100).round(0) if max_pred > 0 else 0
        
        top_magaziny = recs_df.sort_values(by='Pred_Qty_30_days', ascending=False).rename(columns={
            'Magazin': '–ë—É—Ç–∏–∫', 'Pred_Qty_30_days': '–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)', 'Rating_%': '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)'
        })

        st.subheader("üéâ –í–æ—Ç –ª—É—á—à–∏–µ –º–µ—Å—Ç–∞ –¥–ª—è —Ç–≤–æ–µ–π –Ω–æ–≤–∏–Ω–∫–∏! üéâ")
        st.dataframe(top_magaziny[['–ë—É—Ç–∏–∫', '–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)', '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)']].style.highlight_max(
            subset=['–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)'], color='#f8bbd0', axis=0
        ).format({'–ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–æ–¥–∞–∂ (30 –¥–Ω–µ–π, —à—Ç.)': '{:.0f}', '–†–µ–π—Ç–∏–Ω–≥ —É—Å–ø–µ—Ö–∞ (%)': '{:.0f}%'}), use_container_width=True)
else:
    if not dataset_file:
        st.info("üíã –ü—Ä–∏–≤–µ—Ç! –ó–∞–≥—Ä—É–∑–∏ —Ñ–∞–π–ª–∏–∫, –∞ –ø–æ—Ç–æ–º –ø–æ–º–æ–≥–∏ –º–Ω–µ –ø–æ–Ω—è—Ç—å, –≥–¥–µ –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ.")
